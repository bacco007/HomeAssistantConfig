import json
import logging
import asyncio
import contextlib
import re
from datetime import datetime, timedelta
from typing import Any, Callable, Optional
from collections import deque
from urllib.parse import urljoin
from pathlib import Path
import time

import async_timeout
from homeassistant.config_entries import ConfigEntry
from homeassistant.core import HomeAssistant
from homeassistant.helpers.aiohttp_client import async_get_clientsession
from homeassistant.helpers.event import async_track_time_interval
from homeassistant.helpers.update_coordinator import DataUpdateCoordinator, UpdateFailed
from homeassistant.util import dt as dt_util

from .const import (
    API_URL,
    CONSTRUCTOR_STANDINGS_URL,
    DOMAIN,
    DRIVER_STANDINGS_URL,
    LAST_RACE_RESULTS_URL,
    LIVETIMING_INDEX_URL,
    PLATFORMS,
    SEASON_RESULTS_URL,
    SPRINT_RESULTS_URL,
    LATEST_TRACK_STATUS,
    FIA_DOCUMENTS_BASE_URL,
    FIA_SEASON_LIST_URL,
    FIA_SEASON_FALLBACK_URL,
    FIA_DOCS_POLL_INTERVAL,
    FIA_DOCS_FETCH_TIMEOUT,
    CONF_OPERATION_MODE,
    CONF_REPLAY_FILE,
    DEFAULT_OPERATION_MODE,
    OPERATION_MODE_DEVELOPMENT,
    OPERATION_MODE_LIVE,
    ENABLE_DEVELOPMENT_MODE_UI,
)
from .signalr import LiveBus
from .replay import ReplaySignalRClient
from .live_window import LiveSessionSupervisor, LiveAvailabilityTracker
from .helpers import (
    build_user_agent,
    fetch_json,
    fetch_text,
    parse_fia_documents,
    PersistentCache,
)
from .live_delay import LiveDelayController
from .calibration import LiveDelayCalibrationManager

_LOGGER = logging.getLogger(__name__)

_JOLPICA_STATS_KEY = "__jolpica_stats__"


def _ensure_jolpica_stats_reporting(hass: HomeAssistant) -> None:
    """Register a dev-only periodic log of Jolpica network MISS counts."""
    if not ENABLE_DEVELOPMENT_MODE_UI:
        return
    root = hass.data.setdefault(DOMAIN, {})
    stats = root.get(_JOLPICA_STATS_KEY)
    if isinstance(stats, dict) and callable(stats.get("unsub")):
        return

    root[_JOLPICA_STATS_KEY] = {
        "since": dt_util.utcnow().isoformat(),
        "unsub": None,
    }

    async def _log_and_reset(_now) -> None:
        # Snapshot and reset counts (counts live in hass.data[DOMAIN][_JOLPICA_STATS_KEY])
        root2 = hass.data.get(DOMAIN, {}) or {}
        s = root2.get(_JOLPICA_STATS_KEY) or {}
        counts = s.get("counts") if isinstance(s, dict) else None
        if not isinstance(counts, dict) or not counts:
            # Still update since to avoid misleading "since" windows.
            try:
                s["since"] = dt_util.utcnow().isoformat()
            except Exception:
                pass
            return

        total = 0
        try:
            total = int(sum(int(v) for v in counts.values()))
        except Exception:
            total = 0

        # Top endpoints by MISS count
        try:
            top = sorted(counts.items(), key=lambda kv: int(kv[1]), reverse=True)[:10]
        except Exception:
            top = []

        since = s.get("since")
        until = dt_util.utcnow().isoformat()
        _LOGGER.info(
            "Jolpica MISS summary (dev) since=%s until=%s total=%s top=%s",
            since,
            until,
            total,
            [(k, int(v)) for k, v in top],
        )

        # Reset
        try:
            s["counts"] = {}
            s["since"] = until
        except Exception:
            pass

    unsub = async_track_time_interval(hass, _log_and_reset, timedelta(days=1))
    try:
        root[_JOLPICA_STATS_KEY]["unsub"] = unsub
    except Exception:
        pass

# Keep treating the current Grand Prix as "next" for a short period after
# lights out, so helpers and sensors do not jump to the following weekend
# immediately when a race starts.
RACE_SWITCH_GRACE = timedelta(hours=3)


class CoordinatorLogger(logging.LoggerAdapter):
    """Logger adapter that can suppress noisy manual-update debug lines."""

    def __init__(
        self,
        logger: logging.Logger,
        *,
        suppress_manual: bool = False,
        extra: dict | None = None,
    ) -> None:
        super().__init__(logger, extra or {})
        self._suppress_manual = suppress_manual

    def debug(self, msg: str, *args, **kwargs):
        if (
            self._suppress_manual
            and isinstance(msg, str)
            and msg.startswith("Manually updated ")
        ):
            return
        super().debug(msg, *args, **kwargs)


def coordinator_logger(name: str, *, suppress_manual: bool = False) -> CoordinatorLogger:
    return CoordinatorLogger(
        logging.getLogger(f"{__name__}.{name}"),
        suppress_manual=suppress_manual,
    )


async def async_setup_entry(hass: HomeAssistant, entry: ConfigEntry) -> bool:
    """Set up integration via config flow."""
    # Dev-only: periodically report how many Jolpica requests actually hit the network.
    _ensure_jolpica_stats_reporting(hass)
    # Normalize enabled sensors early so we can avoid unnecessary Jolpica calls.
    allowed_enabled = {
        "next_race",
        "current_season",
        "driver_standings",
        "constructor_standings",
        "weather",
        "track_weather",
        "race_lap_count",
        "driver_list",
        "current_tyres",
        "last_race_results",
        "season_results",
        "sprint_results",
        "driver_points_progression",
        "constructor_points_progression",
        "race_week",
        "track_status",
        "session_status",
        "current_session",
        "safety_car",
        "fia_documents",
        "race_control",
        "top_three",
        "team_radio",
        "pitstops",
        "championship_prediction",
        "live_timing_diagnostics",
    }
    raw_enabled = entry.data.get("enabled_sensors") or []
    enabled: list[str] = []
    seen_enabled: set[str] = set()
    for key in raw_enabled:
        if key == "next_session":
            key = "next_race"
        if key in allowed_enabled and key not in seen_enabled:
            enabled.append(key)
            seen_enabled.add(key)

    # Determine which Jolpica/Ergast coordinators are actually required.
    # Note: we also create the "current season" coordinator when season/sprint results
    # are enabled, because it is used to detect season rollovers and to derive the
    # authoritative season for season-scoped endpoints.
    need_race = any(
        k in enabled
        for k in (
            "next_race",
            "current_season",
            "weather",
            "race_week",
            "fia_documents",
            "driver_points_progression",
            "constructor_points_progression",
            "season_results",
            "sprint_results",
        )
    )
    need_driver = any(k in enabled for k in ("driver_standings", "driver_points_progression"))
    need_constructor = any(
        k in enabled for k in ("constructor_standings", "constructor_points_progression")
    )
    need_last_race = "last_race_results" in enabled
    need_season_results = any(
        k in enabled for k in ("season_results", "driver_points_progression", "constructor_points_progression")
    )
    need_sprint_results = any(
        k in enabled for k in ("sprint_results", "driver_points_progression", "constructor_points_progression")
    )
    need_fia_docs = "fia_documents" in enabled

    # Jolpica/Ergast TTL strategy (network-efficient; dashboards can tolerate delay).
    # Units: seconds.
    TTL_CURRENT = 24 * 3600  # current season schedule (rarely changes)
    TTL_STANDINGS = 24 * 3600  # standings change after race weekends
    TTL_LAST_RESULTS = 24 * 3600
    TTL_SPRINT = 24 * 3600
    # Season results are paginated; we refresh the latest page more often inside the coordinator.
    TTL_SEASON_STABLE_PAGE = 30 * 24 * 3600  # older pages: effectively static
    TTL_SEASON_RECENT_PAGE = 24 * 3600       # second-to-last-ish pages
    TTL_SEASON_LATEST_PAGE = 6 * 3600        # latest page: updated after weekends

    # Build custom User-Agent for Jolpica/Ergast. Note: HA's async_create_clientsession
    # does not reliably override the default UA in recent core versions, so we apply
    # this UA per request in the coordinators instead.
    ua_string = await build_user_agent(hass)
    http_session = async_get_clientsession(hass)
    _LOGGER.debug("Configured User-Agent for Jolpica/Ergast (per-request): %s", ua_string)

    # Per-entry shared HTTP cache and in-flight maps (for Jolpica/Ergast only)
    http_cache: dict = {}
    http_inflight: dict = {}
    # Persistent cache (across restarts) for rarely-changing endpoints
    persisted = PersistentCache(hass, entry.entry_id)
    persisted_map = await persisted.load()

    # Seed in-memory cache from persisted content with conservative startup TTLs
    try:
        from yarl import URL
        from time import monotonic as _mono
        now = _mono()
        wall_now = time.time()

        def _startup_ttl_for_key(k: str) -> int:
            """Return TTL for persisted cache entries (seconds).

            This is a conservative mapping that favors fewer network requests
            while ensuring the newest season results page refreshes within hours.
            """
            kk = str(k)
            if "/ergast/f1/current.json" in kk:
                return TTL_CURRENT
            if "/ergast/f1/current/driverstandings.json" in kk or "/ergast/f1/current/constructorstandings.json" in kk:
                return TTL_STANDINGS
            if "/ergast/f1/current/last/results.json" in kk:
                return TTL_LAST_RESULTS
            if "/ergast/f1/current/sprint.json" in kk:
                return TTL_SPRINT
            if "/ergast/f1/current/results.json" in kk:
                # Best-effort per-page TTL from offset (latest pages have higher offsets).
                try:
                    q = URL(kk).query
                    offset_raw = str(q.get("offset") or "0")
                    offset = int(offset_raw) if offset_raw.isdigit() else 0
                except Exception:
                    offset = 0
                # Heuristic: higher offsets tend to be nearer the latest results.
                if offset >= 300:
                    return TTL_SEASON_LATEST_PAGE
                if offset >= 100:
                    return TTL_SEASON_RECENT_PAGE
                return 7 * 24 * 3600
            # Default: keep a modest TTL
            return 6 * 3600
        for k, v in (persisted_map or {}).items():
            data = v.get("data") if isinstance(v, dict) else None
            if data is None:
                continue
            ttl = int(_startup_ttl_for_key(str(k)) or 0)
            saved_at = None
            try:
                saved_at = float(v.get("saved_at")) if isinstance(v, dict) else None
            except Exception:
                saved_at = None
            # Apply remaining TTL relative to saved_at, so old persisted data does not
            # get an artificially "fresh" expiry after restarts.
            try:
                age = max(0.0, wall_now - float(saved_at)) if saved_at else 0.0
            except Exception:
                age = 0.0
            remaining = max(0.0, float(ttl) - float(age))
            http_cache[k] = (now + remaining, data)
        if _LOGGER.isEnabledFor(logging.DEBUG):
            _LOGGER.debug("Seeded in-memory cache from persistent store with %d keys", len(http_cache))
    except Exception:
        pass

    race_coordinator = (
        F1DataCoordinator(
            hass,
            API_URL,
            "F1 Race Data Coordinator",
            session=http_session,
            user_agent=ua_string,
            cache=http_cache,
            inflight=http_inflight,
            ttl_seconds=TTL_CURRENT,
            persist_map=persisted_map,
            persist_save=persisted.schedule_save,
            config_entry=entry,
        )
        if need_race
        else None
    )
    driver_coordinator = (
        F1DataCoordinator(
            hass,
            DRIVER_STANDINGS_URL,
            "F1 Driver Standings Coordinator",
            session=http_session,
            user_agent=ua_string,
            cache=http_cache,
            inflight=http_inflight,
            ttl_seconds=TTL_STANDINGS,
            persist_map=persisted_map,
            persist_save=persisted.schedule_save,
            config_entry=entry,
        )
        if need_driver
        else None
    )
    constructor_coordinator = (
        F1DataCoordinator(
            hass,
            CONSTRUCTOR_STANDINGS_URL,
            "F1 Constructor Standings Coordinator",
            session=http_session,
            user_agent=ua_string,
            cache=http_cache,
            inflight=http_inflight,
            ttl_seconds=TTL_STANDINGS,
            persist_map=persisted_map,
            persist_save=persisted.schedule_save,
            config_entry=entry,
        )
        if need_constructor
        else None
    )
    last_race_coordinator = (
        F1DataCoordinator(
            hass,
            LAST_RACE_RESULTS_URL,
            "F1 Last Race Results Coordinator",
            session=http_session,
            user_agent=ua_string,
            cache=http_cache,
            inflight=http_inflight,
            ttl_seconds=TTL_LAST_RESULTS,
            persist_map=persisted_map,
            persist_save=persisted.schedule_save,
            config_entry=entry,
        )
        if need_last_race
        else None
    )
    season_results_coordinator = (
        F1SeasonResultsCoordinator(
            hass,
            SEASON_RESULTS_URL,
            "F1 Season Results Coordinator",
            session=http_session,
            user_agent=ua_string,
            cache=http_cache,
            inflight=http_inflight,
            ttl_seconds=TTL_SEASON_LATEST_PAGE,
            ttl_stable=TTL_SEASON_STABLE_PAGE,
            ttl_recent=TTL_SEASON_RECENT_PAGE,
            ttl_latest=TTL_SEASON_LATEST_PAGE,
            persist_map=persisted_map,
            persist_save=persisted.schedule_save,
            config_entry=entry,
            season_source=race_coordinator,
        )
        if need_season_results
        else None
    )
    sprint_results_coordinator = (
        F1SprintResultsCoordinator(
            hass,
            SPRINT_RESULTS_URL,
            "F1 Sprint Results Coordinator",
            session=http_session,
            user_agent=ua_string,
            cache=http_cache,
            inflight=http_inflight,
            ttl_seconds=TTL_SPRINT,
            persist_map=persisted_map,
            persist_save=persisted.schedule_save,
            config_entry=entry,
        )
        if need_sprint_results
        else None
    )
    fia_documents_coordinator = (
        FiaDocumentsCoordinator(
        hass,
        race_coordinator,
        session=http_session,
        cache=http_cache,
        inflight=http_inflight,
        ttl_seconds=FIA_DOCS_POLL_INTERVAL,
        persist_map=persisted_map,
        persist_save=persisted.schedule_save,
        config_entry=entry,
        )
        if (need_fia_docs and race_coordinator is not None)
        else None
    )
    year = dt_util.utcnow().year
    session_coordinator = LiveSessionCoordinator(hass, year, config_entry=entry)
    enable_rc = entry.data.get("enable_race_control", False)
    configured_delay = int(entry.data.get("live_delay_seconds", 0) or 0)
    delay_controller = LiveDelayController(hass, entry.entry_id)
    live_delay = await delay_controller.async_initialize(configured_delay)
    operation_mode = entry.data.get(CONF_OPERATION_MODE, DEFAULT_OPERATION_MODE)
    replay_source = str(entry.data.get(CONF_REPLAY_FILE, "") or "").strip()
    transport_factory = None
    if operation_mode == OPERATION_MODE_DEVELOPMENT:
        if not replay_source:
            _LOGGER.warning(
                "Development mode selected but no replay file configured; falling back to live SignalR"
            )
            operation_mode = OPERATION_MODE_LIVE
        else:
            replay_path = Path(replay_source).expanduser()
            if not replay_path.exists():
                _LOGGER.warning(
                    "Replay file %s not found; falling back to live SignalR",
                    replay_path,
                )
                operation_mode = OPERATION_MODE_LIVE
            else:
                _LOGGER.info(
                    "Starting F1 Sensor in development replay mode using %s",
                    replay_path,
                )

                def _transport_factory() -> ReplaySignalRClient:
                    return ReplaySignalRClient(hass, replay_path)

                transport_factory = _transport_factory
    track_status_coordinator = None
    session_status_coordinator = None
    session_info_coordinator = None
    weather_data_coordinator = None
    lap_count_coordinator = None
    race_control_coordinator = None
    top_three_coordinator = None
    hass.data[LATEST_TRACK_STATUS] = None
    # Create shared LiveBus (single SignalR connection). Live mode defers start to supervisor.
    session = async_get_clientsession(hass)
    live_bus = LiveBus(hass, session, transport_factory=transport_factory)
    live_supervisor: LiveSessionSupervisor | None = None
    live_state: LiveAvailabilityTracker
    if operation_mode == OPERATION_MODE_LIVE:
        live_supervisor = LiveSessionSupervisor(
            hass,
            session_coordinator,
            live_bus,
            http_session=session,
        )
        await live_supervisor.async_start()
        live_state = live_supervisor.availability
    else:
        await live_bus.start()
        live_state = LiveAvailabilityTracker()
        live_state.set_state(True, "replay-mode")

    def _reload_entry():
        hass.async_create_task(hass.config_entries.async_reload(entry.entry_id))

    calibration_manager = LiveDelayCalibrationManager(
        hass,
        delay_controller,
        bus=live_bus,
        timeout_seconds=120,
        reload_callback=_reload_entry,
    )

    if enable_rc:
        track_status_coordinator = TrackStatusCoordinator(
            hass,
            session_coordinator,
            live_delay,
            bus=live_bus,
            config_entry=entry,
            delay_controller=delay_controller,
            live_state=live_state,
        )
        session_status_coordinator = SessionStatusCoordinator(
            hass,
            session_coordinator,
            live_delay,
            bus=live_bus,
            config_entry=entry,
            delay_controller=delay_controller,
            live_state=live_state,
        )
        session_info_coordinator = SessionInfoCoordinator(
            hass,
            session_coordinator,
            live_delay,
            bus=live_bus,
            config_entry=entry,
            delay_controller=delay_controller,
            live_state=live_state,
        )
        race_control_coordinator = RaceControlCoordinator(
            hass,
            session_coordinator,
            live_delay,
            bus=live_bus,
            config_entry=entry,
            delay_controller=delay_controller,
            live_state=live_state,
        )
        weather_data_coordinator = WeatherDataCoordinator(
            hass,
            session_coordinator,
            live_delay,
            bus=live_bus,
            config_entry=entry,
            delay_controller=delay_controller,
            live_state=live_state,
        )
        lap_count_coordinator = LapCountCoordinator(
            hass,
            session_coordinator,
            live_delay,
            bus=live_bus,
            config_entry=entry,
            delay_controller=delay_controller,
            live_state=live_state,
        )

    if race_coordinator:
        await race_coordinator.async_config_entry_first_refresh()
    if driver_coordinator:
        await driver_coordinator.async_config_entry_first_refresh()
    if constructor_coordinator:
        await constructor_coordinator.async_config_entry_first_refresh()
    if last_race_coordinator:
        await last_race_coordinator.async_config_entry_first_refresh()
    if season_results_coordinator:
        await season_results_coordinator.async_config_entry_first_refresh()
    if sprint_results_coordinator:
        await sprint_results_coordinator.async_config_entry_first_refresh()
    if fia_documents_coordinator:
        await fia_documents_coordinator.async_config_entry_first_refresh()
    await session_coordinator.async_config_entry_first_refresh()
    if track_status_coordinator:
        await track_status_coordinator.async_config_entry_first_refresh()
    if session_status_coordinator:
        await session_status_coordinator.async_config_entry_first_refresh()
    if session_info_coordinator:
        await session_info_coordinator.async_config_entry_first_refresh()
    if race_control_coordinator:
        await race_control_coordinator.async_config_entry_first_refresh()
    if weather_data_coordinator:
        await weather_data_coordinator.async_config_entry_first_refresh()
    if lap_count_coordinator:
        await lap_count_coordinator.async_config_entry_first_refresh()

    # Conditionally create live drivers coordinator only if any drivers-related sensors are enabled
    # Only create drivers coordinator if driver_list is enabled (TEMP: race_order/driver_favorites disabled)
    need_drivers = any(k in enabled for k in ("driver_list",))
    need_top_three = any(k in enabled for k in ("top_three",))
    need_team_radio = any(k in enabled for k in ("team_radio",))
    need_pitstops = any(k in enabled for k in ("pitstops",))
    need_championship_prediction = any(k in enabled for k in ("championship_prediction",))
    drivers_coordinator = None
    if need_drivers:
        drivers_coordinator = LiveDriversCoordinator(
            hass,
            session_coordinator,
            delay_seconds=live_delay,
            bus=live_bus,
            config_entry=entry,
            delay_controller=delay_controller,
            live_state=live_state,
        )
        await drivers_coordinator.async_config_entry_first_refresh()

    # Conditionally create TopThree coordinator only if sensor is enabled
    if enable_rc and need_top_three:
        top_three_coordinator = TopThreeCoordinator(
            hass,
            session_coordinator,
            live_delay,
            bus=live_bus,
            config_entry=entry,
            delay_controller=delay_controller,
            live_state=live_state,
        )
        await top_three_coordinator.async_config_entry_first_refresh()

    team_radio_coordinator = None
    if need_team_radio:
        team_radio_coordinator = TeamRadioCoordinator(
            hass,
            session_coordinator,
            live_delay,
            bus=live_bus,
            config_entry=entry,
            delay_controller=delay_controller,
            live_state=live_state,
        )
        await team_radio_coordinator.async_config_entry_first_refresh()

    pitstop_coordinator = None
    if need_pitstops:
        pitstop_coordinator = PitStopCoordinator(
            hass,
            session_coordinator,
            live_delay,
            bus=live_bus,
            config_entry=entry,
            delay_controller=delay_controller,
            live_state=live_state,
            history_limit=10,
        )
        await pitstop_coordinator.async_config_entry_first_refresh()

    championship_prediction_coordinator = None
    if need_championship_prediction:
        championship_prediction_coordinator = ChampionshipPredictionCoordinator(
            hass,
            session_coordinator,
            live_delay,
            bus=live_bus,
            config_entry=entry,
            delay_controller=delay_controller,
            live_state=live_state,
        )
        await championship_prediction_coordinator.async_config_entry_first_refresh()

    hass.data.setdefault(DOMAIN, {})[entry.entry_id] = {
        "http_session": http_session,
        "user_agent": ua_string,
        "http_cache": http_cache,
        "http_inflight": http_inflight,
        "http_persist": persisted_map,
        "race_coordinator": race_coordinator,
        "driver_coordinator": driver_coordinator,
        "constructor_coordinator": constructor_coordinator,
        "last_race_coordinator": last_race_coordinator,
        "season_results_coordinator": season_results_coordinator,
        "sprint_results_coordinator": sprint_results_coordinator,
        "session_coordinator": session_coordinator,
        "track_status_coordinator": track_status_coordinator,
        "session_status_coordinator": session_status_coordinator,
        "session_info_coordinator": session_info_coordinator,
        "race_control_coordinator": race_control_coordinator if enable_rc else None,
        "weather_data_coordinator": weather_data_coordinator if enable_rc else None,
        "lap_count_coordinator": lap_count_coordinator if enable_rc else None,
        "top_three_coordinator": top_three_coordinator,
        "team_radio_coordinator": team_radio_coordinator,
        "pitstop_coordinator": pitstop_coordinator,
        "championship_prediction_coordinator": championship_prediction_coordinator,
        "drivers_coordinator": drivers_coordinator,
        "fia_documents_coordinator": fia_documents_coordinator,
        "live_bus": live_bus,
        "live_supervisor": live_supervisor,
        "live_state": live_state,
        "operation_mode": operation_mode,
        "replay_file": replay_source,
        "live_delay_controller": delay_controller,
        "calibration_manager": calibration_manager,
    }

    await hass.config_entries.async_forward_entry_setups(entry, PLATFORMS)
    return True


class WeatherDataCoordinator(DataUpdateCoordinator):
    """Coordinator for WeatherData updates using SignalR, mirrors Track/Session behavior."""

    def __init__(
        self,
        hass: HomeAssistant,
        session_coord: 'LiveSessionCoordinator',
        delay_seconds: int = 0,
        bus: LiveBus | None = None,
        config_entry: ConfigEntry | None = None,
        delay_controller: LiveDelayController | None = None,
        live_state: LiveAvailabilityTracker | None = None,
    ):
        super().__init__(
            hass,
            coordinator_logger("weather", suppress_manual=True),
            name="F1 Weather Data Coordinator",
            update_interval=None,
            config_entry=config_entry,
        )
        self._session = async_get_clientsession(hass)
        self._session_coord = session_coord
        self.available = True
        self._last_message = None
        self.data_list: list[dict] = []
        self._deliver_handle: Optional[asyncio.Handle] = None
        self._bus = bus
        self._unsub: Optional[Callable[[], None]] = None
        self._delay_listener: Optional[Callable[[], None]] = None
        self._delay = max(0, int(delay_seconds or 0))
        if delay_controller is not None:
            self._delay_listener = delay_controller.add_listener(self.set_delay)
        self._live_state_unsub: Optional[Callable[[], None]] = None
        if live_state is not None:
            self._live_state_unsub = live_state.add_listener(self._handle_live_state)

    async def async_close(self, *_):
        if self._unsub:
            try:
                self._unsub()
            except Exception:
                pass
            self._unsub = None
        if self._deliver_handle:
            try:
                self._deliver_handle.cancel()
            except Exception:
                pass
            self._deliver_handle = None
        if self._delay_listener:
            try:
                self._delay_listener()
            except Exception:
                pass
            self._delay_listener = None
        if self._live_state_unsub:
            try:
                self._live_state_unsub()
            except Exception:
                pass
            self._live_state_unsub = None
        if self._delay_listener:
            try:
                self._delay_listener()
            except Exception:
                pass
            self._delay_listener = None

    async def _async_update_data(self):
        return self._last_message

    def _on_bus_message(self, msg: dict) -> None:
        if not isinstance(msg, dict):
            return
        # Skip duplicate snapshots without timestamp to avoid heartbeat churn
        if self._should_skip_duplicate(msg):
            return
        if self._delay > 0:
            try:
                if self._deliver_handle:
                    self._deliver_handle.cancel()
            except Exception:
                pass
            self._deliver_handle = self.hass.loop.call_later(
                self._delay, lambda m=msg: self._deliver(m)
            )
        else:
            # Coalesce in same loop tick
            try:
                if self._deliver_handle:
                    self._deliver_handle.cancel()
            except Exception:
                pass
            self._deliver_handle = self.hass.loop.call_soon(lambda m=msg: self._deliver(m))

    @staticmethod
    def _has_timestamp(d: dict) -> bool:
        try:
            return any(k in d for k in ("Utc", "utc", "processedAt", "timestamp"))
        except Exception:
            return False

    def _should_skip_duplicate(self, msg: dict) -> bool:
        """Return True if msg is duplicate of last and has no timestamp.

        Compares core weather fields to avoid treating heartbeat-returned snapshots
        as fresh data.
        """
        if not isinstance(msg, dict):
            return False
        if self._has_timestamp(msg):
            return False
        last = self._last_message if isinstance(self._last_message, dict) else None
        if not last:
            return False
        keys = (
            "AirTemp",
            "TrackTemp",
            "Humidity",
            "Pressure",
            "Rainfall",
            "WindDirection",
            "WindSpeed",
        )
        try:
            for k in keys:
                if str(last.get(k)) != str(msg.get(k)):
                    return False
            return True
        except Exception:
            return False

    @staticmethod
    def _parse_message(data):
        if not isinstance(data, dict):
            return None
        messages = data.get("M")
        if isinstance(messages, list):
            for update in messages:
                args = update.get("A", [])
                if len(args) >= 2 and args[0] == "WeatherData":
                    return args[1]
        result = data.get("R")
        if isinstance(result, dict) and "WeatherData" in result:
            return result.get("WeatherData")
        return None

    def _deliver(self, msg: dict) -> None:
        self.available = True
        self._last_message = msg
        self.data_list = [msg]
        self.async_set_updated_data(msg)
        if _LOGGER.isEnabledFor(logging.DEBUG):
            try:
                keys = [k for k in (msg or {}).keys()][:6]
                _LOGGER.debug(
                    "WeatherData delivered at %s keys=%s",
                    dt_util.utcnow().isoformat(timespec="seconds"),
                    keys,
                )
            except Exception:
                pass

    async def async_config_entry_first_refresh(self):
        await super().async_config_entry_first_refresh()
        # Subscribe to shared live bus
        try:
            self._unsub = (self._bus or self.hass.data.get(DOMAIN, {}).get("live_bus")).subscribe("WeatherData", self._on_bus_message)  # type: ignore[attr-defined]
        except Exception:
            self._unsub = None

    def set_delay(self, seconds: int) -> None:
        new_delay = max(0, int(seconds or 0))
        if new_delay == self._delay:
            return
        self._delay = new_delay
        if self._deliver_handle:
            try:
                self._deliver_handle.cancel()
            except Exception:
                pass
            self._deliver_handle = None

    def _handle_live_state(self, is_live: bool, reason: str | None) -> None:
        # Ignore initial attach callback so we don't mark entities unavailable
        # before the LiveSessionSupervisor has decided whether to arm a window.
        if reason == "init":
            return
        self.available = is_live
        if not is_live:
            self._last_message = None
            self.data_list = []


class RaceControlCoordinator(DataUpdateCoordinator):
    """Coordinator for RaceControlMessages that publishes HA events for new items.

    - Mirrors logging/delay patterns from Track/Session coordinators
    - Publishes Home Assistant events only for new Race Control items (avoids replay on startup)
    """

    def __init__(
        self,
        hass: HomeAssistant,
        session_coord: 'LiveSessionCoordinator',
        delay_seconds: int = 0,
        bus: LiveBus | None = None,
        config_entry: ConfigEntry | None = None,
        delay_controller: LiveDelayController | None = None,
        live_state: LiveAvailabilityTracker | None = None,
    ):
        super().__init__(
            hass,
            coordinator_logger("race_control", suppress_manual=True),
            name="F1 Race Control Coordinator",
            update_interval=None,
            config_entry=config_entry,
        )
        self._session = async_get_clientsession(hass)
        self._session_coord = session_coord
        self.available = True
        self._last_message = None
        self.data_list: list[dict] = []
        self._deliver_handles: list[asyncio.Handle] = []
        self._bus = bus
        self._unsub: Optional[Callable[[], None]] = None
        self._delay_listener: Optional[Callable[[], None]] = None
        self._delay = max(0, int(delay_seconds or 0))
        if delay_controller is not None:
            self._delay_listener = delay_controller.add_listener(self.set_delay)
        # For duplicate filtering and startup replay suppression
        self._seen_ids_set: set[str] = set()
        self._seen_ids_order = deque(maxlen=1024)
        self._startup_cutoff: datetime | None = None
        self._dev_mode = (
            bool(config_entry)
            and config_entry.data.get(CONF_OPERATION_MODE, DEFAULT_OPERATION_MODE)
            == OPERATION_MODE_DEVELOPMENT
        )
        self._live_state_unsub: Optional[Callable[[], None]] = None
        if live_state is not None:
            self._live_state_unsub = live_state.add_listener(self._handle_live_state)

    async def async_close(self, *_):
        if self._unsub:
            try:
                self._unsub()
            except Exception:
                pass
            self._unsub = None
        if self._deliver_handles:
            for handle in list(self._deliver_handles):
                try:
                    handle.cancel()
                except Exception:
                    pass
            self._deliver_handles.clear()
        if self._delay_listener:
            try:
                self._delay_listener()
            except Exception:
                pass
            self._delay_listener = None
        if self._live_state_unsub:
            try:
                self._live_state_unsub()
            except Exception:
                pass
            self._live_state_unsub = None

    async def _async_update_data(self):
        return self._last_message

    @staticmethod
    def _parse_message(data):
        if not isinstance(data, dict):
            return None
        # Live feed entries
        messages = data.get("M")
        if isinstance(messages, list):
            for update in messages:
                args = update.get("A", [])
                if len(args) >= 2 and args[0] == "RaceControlMessages":
                    return args[1]
        # RPC response
        result = data.get("R")
        if isinstance(result, dict) and "RaceControlMessages" in result:
            return result.get("RaceControlMessages")
        return None

    @staticmethod
    def _extract_items(msg) -> list[dict]:
        # RaceControl feed can be a list of entries or a dict with list under key
        if isinstance(msg, list):
            return [m for m in msg if isinstance(m, dict)]
        if isinstance(msg, dict):
            # Some payloads contain { "Messages": [ ... ] }
            messages = msg.get("Messages")
            if isinstance(messages, list):
                return [m for m in messages if isinstance(m, dict)]
            # Some payloads contain { "Messages": { "1": {...}, "2": {...}, ... } }
            if isinstance(messages, dict) and messages:
                try:
                    numeric_keys = [k for k in messages.keys() if str(k).isdigit()]
                    # Sort by numeric key to preserve order if automations iterate
                    numeric_keys.sort(key=lambda x: int(x))
                    result: list[dict] = []
                    for key in numeric_keys:
                        val = messages.get(key)
                        if isinstance(val, dict):
                            item = dict(val)
                            # Provide stable id if not present
                            item.setdefault("id", int(key))
                            result.append(item)
                    if result:
                        return result
                except Exception:
                    # Fall through to wrapper-as-item if something unexpected happens
                    pass
            # Or a single message
            return [msg]
        return []

    @staticmethod
    def _message_id(item: dict) -> str:
        # Compose a stable id from typical fields
        try:
            ts = str(
                item.get("Utc")
                or item.get("utc")
                or item.get("processedAt")
                or item.get("timestamp")
                or ""
            )
            text = str(item.get("Message") or item.get("Text") or item.get("Flag") or "")
            cat = str(item.get("Category") or item.get("CategoryType") or "")
            return f"{ts}|{cat}|{text}"
        except Exception:
            return json.dumps(item, sort_keys=True, default=str)

    def _on_bus_message(self, msg: dict) -> None:
        if not isinstance(msg, (dict, list)):
            return
        items = self._extract_items(msg)
        if not items:
            return
        for item in items:
            # Startup cutoff: ignore historical within 30s before now
            try:
                ts_raw = (
                    item.get("Utc")
                    or item.get("utc")
                    or item.get("processedAt")
                    or item.get("timestamp")
                )
                if ts_raw:
                    ts = datetime.fromisoformat(str(ts_raw).replace("Z", "+00:00"))
                    if ts.tzinfo is None:
                        from datetime import timezone as _tz
                        ts = ts.replace(tzinfo=_tz.utc)
                    if self._startup_cutoff and ts < self._startup_cutoff:
                        continue
            except Exception:
                pass
            ident = self._message_id(item)
            if ident in self._seen_ids_set:
                continue
            # Evict if needed then add
            if len(self._seen_ids_order) == self._seen_ids_order.maxlen:
                try:
                    old = self._seen_ids_order.popleft()
                    self._seen_ids_set.discard(old)
                except Exception:
                    pass
            self._seen_ids_order.append(ident)
            self._seen_ids_set.add(ident)
            # Schedule/coalesce delivery
            self._schedule_deliver(item)

    def _schedule_deliver(self, item: dict) -> None:
        handle: asyncio.Handle | None = None

        def _callback(m=item):
            nonlocal handle
            try:
                self._deliver(m)
            finally:
                if handle:
                    try:
                        self._deliver_handles.remove(handle)
                    except ValueError:
                        pass
                    handle = None

        loop = self.hass.loop
        if self._delay > 0:
            handle = loop.call_later(self._delay, _callback)
        else:
            handle = loop.call_soon(_callback)
        self._deliver_handles.append(handle)

    def set_delay(self, seconds: int) -> None:
        new_delay = max(0, int(seconds or 0))
        if new_delay == self._delay:
            return
        self._delay = new_delay
        if self._deliver_handles:
            for handle in list(self._deliver_handles):
                try:
                    handle.cancel()
                except Exception:
                    pass
            self._deliver_handles.clear()

    def _handle_live_state(self, is_live: bool, reason: str | None) -> None:
        if reason == "init":
            return
        self.available = is_live
        if not is_live:
            self._last_message = None
            self.data_list = []

    def _deliver(self, item: dict) -> None:
        self.available = True
        # Maintain last message for visibility and parity with other coordinators
        self._last_message = item
        self.data_list = [item]
        self.async_set_updated_data(item)
        if _LOGGER.isEnabledFor(logging.DEBUG):
            try:
                cat = item.get("Category") or item.get("CategoryType")
                flag = item.get("Flag")
                text = item.get("Message") or item.get("Text")
                ts = item.get("Utc") or item.get("utc") or item.get("timestamp")
                _LOGGER.debug(
                    "RaceControl delivered at %s ts=%s cat=%s flag=%s text=%s",
                    dt_util.utcnow().isoformat(timespec="seconds"),
                    ts,
                    cat,
                    flag,
                    (str(text)[:60] if isinstance(text, str) else text),
                )
            except Exception:
                pass
        # Publish on HA event bus with a consistent event name
        try:
            self.hass.bus.async_fire(
                f"{DOMAIN}_race_control_event",
                {
                    "message": item,
                    "received_at": dt_util.utcnow().isoformat(timespec="seconds"),
                },
            )
        except Exception:
            _LOGGER.debug("RaceControl: Failed to publish event for item")

    async def async_config_entry_first_refresh(self):
        await super().async_config_entry_first_refresh()
        # Establish startup cutoff for replay suppression
        if self._dev_mode:
            self._startup_cutoff = None
        else:
            try:
                from datetime import timezone
                t0 = datetime.now(timezone.utc)
                self._startup_cutoff = t0 - timedelta(seconds=30)
            except Exception:
                self._startup_cutoff = None
        # Subscribe to LiveBus
        try:
            self._unsub = (self._bus or self.hass.data.get(DOMAIN, {}).get("live_bus")).subscribe("RaceControlMessages", self._on_bus_message)  # type: ignore[attr-defined]
        except Exception:
            self._unsub = None

class LapCountCoordinator(DataUpdateCoordinator):
    """Coordinator for LapCount updates using SignalR, mirrors other live feeds."""

    def __init__(
        self,
        hass: HomeAssistant,
        session_coord: 'LiveSessionCoordinator',
        delay_seconds: int = 0,
        bus: LiveBus | None = None,
        config_entry: ConfigEntry | None = None,
        delay_controller: LiveDelayController | None = None,
        live_state: LiveAvailabilityTracker | None = None,
    ):
        super().__init__(
            hass,
            coordinator_logger("lap_count", suppress_manual=True),
            name="F1 Lap Count Coordinator",
            update_interval=None,
            config_entry=config_entry,
        )
        self._session = async_get_clientsession(hass)
        self._session_coord = session_coord
        self.available = True
        self._last_message = None
        self.data_list: list[dict] = []
        self._deliver_handle: Optional[asyncio.Handle] = None
        self._bus = bus
        self._unsub: Optional[Callable[[], None]] = None
        self._delay_listener: Optional[Callable[[], None]] = None
        self._delay = max(0, int(delay_seconds or 0))
        if delay_controller is not None:
            self._delay_listener = delay_controller.add_listener(self.set_delay)
        self._live_state_unsub: Optional[Callable[[], None]] = None
        if live_state is not None:
            self._live_state_unsub = live_state.add_listener(self._handle_live_state)

    async def async_close(self, *_):
        if self._unsub:
            try:
                self._unsub()
            except Exception:
                pass
            self._unsub = None
        if self._deliver_handle:
            try:
                self._deliver_handle.cancel()
            except Exception:
                pass
            self._deliver_handle = None
        if self._delay_listener:
            try:
                self._delay_listener()
            except Exception:
                pass
            self._delay_listener = None
        if self._live_state_unsub:
            try:
                self._live_state_unsub()
            except Exception:
                pass
            self._live_state_unsub = None

    async def _async_update_data(self):
        return self._last_message

    @staticmethod
    def _parse_message(data):
        if not isinstance(data, dict):
            return None
        messages = data.get("M")
        if isinstance(messages, list):
            for update in messages:
                args = update.get("A", [])
                if len(args) >= 2 and args[0] == "LapCount":
                    return args[1]
        result = data.get("R")
        if isinstance(result, dict) and "LapCount" in result:
            return result.get("LapCount")
        return None

    def _on_bus_message(self, msg: dict) -> None:
        if not isinstance(msg, dict):
            return
        if self._delay > 0:
            try:
                if self._deliver_handle:
                    self._deliver_handle.cancel()
            except Exception:
                pass
            self._deliver_handle = self.hass.loop.call_later(
                self._delay, lambda m=msg: self._deliver(m)
            )
        else:
            try:
                if self._deliver_handle:
                    self._deliver_handle.cancel()
            except Exception:
                pass
            self._deliver_handle = self.hass.loop.call_soon(lambda m=msg: self._deliver(m))

    def _deliver(self, msg: dict) -> None:
        self.available = True
        self._last_message = msg
        self.data_list = [msg]
        self.async_set_updated_data(msg)
        if _LOGGER.isEnabledFor(logging.DEBUG):
            try:
                _LOGGER.debug(
                    "LapCount delivered at %s current=%s total=%s",
                    dt_util.utcnow().isoformat(timespec="seconds"),
                    (msg or {}).get("CurrentLap") or (msg or {}).get("LapCount"),
                    (msg or {}).get("TotalLaps"),
                )
            except Exception:
                pass

    async def async_config_entry_first_refresh(self):
        await super().async_config_entry_first_refresh()
        try:
            self._unsub = (self._bus or self.hass.data.get(DOMAIN, {}).get("live_bus")).subscribe("LapCount", self._on_bus_message)  # type: ignore[attr-defined]
        except Exception:
            self._unsub = None

    def set_delay(self, seconds: int) -> None:
        new_delay = max(0, int(seconds or 0))
        if new_delay == self._delay:
            return
        self._delay = new_delay
        if self._deliver_handle:
            try:
                self._deliver_handle.cancel()
            except Exception:
                pass
            self._deliver_handle = None

    def _handle_live_state(self, is_live: bool, reason: str | None) -> None:
        if reason == "init":
            return
        self.available = is_live
        if not is_live:
            self._last_message = None
            self.data_list = []


class TeamRadioCoordinator(DataUpdateCoordinator):
    """Coordinator for TeamRadio updates using SignalR.

    Normaliserar TeamRadio-flÃ¶det till en enkel struktur:
        data = {
            "latest": { ...normaliserad capture... } | None,
            "history": [ { ...capture... }, ... ],
        }
    """

    def __init__(
        self,
        hass: HomeAssistant,
        session_coord: "LiveSessionCoordinator",
        delay_seconds: int = 0,
        bus: LiveBus | None = None,
        config_entry: ConfigEntry | None = None,
        delay_controller: LiveDelayController | None = None,
        live_state: LiveAvailabilityTracker | None = None,
        history_limit: int = 20,
    ) -> None:
        super().__init__(
            hass,
            coordinator_logger("team_radio", suppress_manual=True),
            name="F1 Team Radio Coordinator",
            update_interval=None,
            config_entry=config_entry,
        )
        self._session = async_get_clientsession(hass)
        self._session_coord = session_coord
        self.available = True
        self._state: dict[str, Any] = {
            "latest": None,
            "history": [],
        }
        self._history_limit = max(1, int(history_limit or 20))
        self._deliver_handle: Optional[asyncio.Handle] = None
        self._bus = bus
        self._unsub: Optional[Callable[[], None]] = None
        self._delay_listener: Optional[Callable[[], None]] = None
        self._delay = max(0, int(delay_seconds or 0))
        if delay_controller is not None:
            self._delay_listener = delay_controller.add_listener(self.set_delay)
        self._config_entry = config_entry
        self._dev_mode = (
            bool(config_entry)
            and config_entry.data.get(CONF_OPERATION_MODE, DEFAULT_OPERATION_MODE)
            == OPERATION_MODE_DEVELOPMENT
        )
        self._replay_static_root: str | None = None
        self._live_state_unsub: Optional[Callable[[], None]] = None
        if live_state is not None:
            self._live_state_unsub = live_state.add_listener(self._handle_live_state)

    async def async_close(self, *_):
        if self._unsub:
            try:
                self._unsub()
            except Exception:
                pass
            self._unsub = None
        if self._deliver_handle:
            try:
                self._deliver_handle.cancel()
            except Exception:
                pass
            self._deliver_handle = None
        if self._delay_listener:
            try:
                self._delay_listener()
            except Exception:
                pass
            self._delay_listener = None
        if self._live_state_unsub:
            try:
                self._live_state_unsub()
            except Exception:
                pass
            self._live_state_unsub = None

    async def _async_update_data(self):
        return self._state

    def _handle_live_state(self, is_live: bool, reason: str | None) -> None:
        if reason == "init":
            return
        self.available = is_live
        if not is_live:
            self._state = {"latest": None, "history": []}

    def set_delay(self, seconds: int) -> None:
        new_delay = max(0, int(seconds or 0))
        if new_delay == self._delay:
            return
        self._delay = new_delay
        if self._deliver_handle:
            try:
                self._deliver_handle.cancel()
            except Exception:
                pass
            self._deliver_handle = None

    def _on_bus_message(self, msg: dict) -> None:
        if not isinstance(msg, dict):
            return
        if self._delay > 0:
            try:
                if self._deliver_handle:
                    self._deliver_handle.cancel()
            except Exception:
                pass
            self._deliver_handle = self.hass.loop.call_later(
                self._delay, lambda m=msg: self._deliver(m)
            )
        else:
            try:
                if self._deliver_handle:
                    self._deliver_handle.cancel()
            except Exception:
                pass
            self._deliver_handle = self.hass.loop.call_soon(
                lambda m=msg: self._deliver(m)
            )

    @staticmethod
    def _normalize_captures(payload: dict) -> list[dict]:
        """Extract a flat list of capture dicts from a TeamRadio payload."""
        if not isinstance(payload, dict):
            return []
        captures = payload.get("Captures")
        static_root = payload.get("_static_root")
        result: list[dict] = []
        try:
            if isinstance(captures, list):
                for item in captures:
                    if isinstance(item, dict):
                        copy = dict(item)
                        if static_root and "_static_root" not in copy:
                            copy["_static_root"] = static_root
                        result.append(copy)
            elif isinstance(captures, dict):
                # Some dumps use numeric keys: {"Captures":{"1":{...},"2":{...}}}
                numeric_keys = [
                    k for k in captures.keys() if str(k).isdigit()
                ]
                if numeric_keys:
                    numeric_keys.sort(key=lambda x: int(x))
                    for key in numeric_keys:
                        val = captures.get(key)
                        if isinstance(val, dict):
                            copy = dict(val)
                            if static_root and "_static_root" not in copy:
                                copy["_static_root"] = static_root
                            result.append(copy)
                else:
                    for val in captures.values():
                        if isinstance(val, dict):
                            copy = dict(val)
                            if static_root and "_static_root" not in copy:
                                copy["_static_root"] = static_root
                            result.append(copy)
        except Exception:
            return result
        return result

    def _deliver(self, msg: dict) -> None:
        self.available = True
        # In replay/development mode, try to provide a static root URL even if the
        # transport did not annotate the payload (robust against file encoding quirks).
        try:
            if (
                self._dev_mode
                and self._replay_static_root
                and isinstance(msg, dict)
                and "_static_root" not in msg
            ):
                msg = dict(msg)
                msg["_static_root"] = self._replay_static_root
        except Exception:
            pass
        captures = self._normalize_captures(msg)
        if not captures:
            return
        # Use the last capture as "latest"
        latest = captures[-1]
        history: list[dict] = list(self._state.get("history") or [])
        history.extend(captures)
        if len(history) > self._history_limit:
            history = history[-self._history_limit :]
        self._state = {
            "latest": latest,
            "history": history,
        }
        self.async_set_updated_data(self._state)
        if _LOGGER.isEnabledFor(logging.DEBUG):
            try:
                _LOGGER.debug(
                    "TeamRadio delivered at %s latest=%s history_len=%s",
                    dt_util.utcnow().isoformat(timespec="seconds"),
                    {
                        "Utc": latest.get("Utc"),
                        "RacingNumber": latest.get("RacingNumber"),
                        "Path": latest.get("Path"),
                    },
                    len(history),
                )
            except Exception:
                pass

    async def async_config_entry_first_refresh(self):
        await super().async_config_entry_first_refresh()
        # Best-effort: derive static root from the replay file's URL header so sensors
        # can build full clip URLs during replay.
        if self._dev_mode and self._config_entry:
            try:
                from pathlib import Path as _Path

                replay_source = str(self._config_entry.data.get(CONF_REPLAY_FILE, "") or "").strip()
                if replay_source:
                    replay_path = _Path(replay_source).expanduser()

                    def _read_static_root() -> str | None:
                        try:
                            with replay_path.open("r", encoding="utf-8") as fh:
                                # Scan a bit deeper than the first non-empty line; some dumps
                                # may have the URL header later (or be prepended with comments).
                                # We keep this bounded to avoid reading huge files in full.
                                max_lines = 500
                                for idx, raw in enumerate(fh):
                                    if idx >= max_lines:
                                        break
                                    line = raw.lstrip("\ufeff").strip()
                                    if not line:
                                        continue
                                    if line.upper().startswith("URL:"):
                                        try:
                                            _, url = line.split(":", 1)
                                        except ValueError:
                                            return None
                                        full_url = url.strip().rstrip("/")
                                        if not full_url:
                                            return None
                                        parts = full_url.split("/")
                                        if len(parts) <= 1:
                                            return None
                                        # Drop the final segment (e.g. TeamRadio.jsonStream)
                                        return "/".join(parts[:-1])
                        except Exception:
                            return None
                        return None

                    static_root = await self.hass.async_add_executor_job(_read_static_root)
                    if static_root:
                        self._replay_static_root = str(static_root)
            except Exception:
                pass
        try:
            self._unsub = (
                self._bus or self.hass.data.get(DOMAIN, {}).get("live_bus")
            ).subscribe("TeamRadio", self._on_bus_message)  # type: ignore[attr-defined]
        except Exception:
            self._unsub = None


class PitStopCoordinator(DataUpdateCoordinator):
    """Coordinator aggregating live pit stops for all cars.

    Exposes:
        data = {
          "total_stops": int,
          "cars": {
            "44": {"count": 2, "stops": [ {stop}, ... ]},
            ...
          },
          "last_update": "2025-12-07T14:07:19+00:00",
        }
    """

    def __init__(
        self,
        hass: HomeAssistant,
        session_coord: "LiveSessionCoordinator",
        delay_seconds: int = 0,
        bus: LiveBus | None = None,
        config_entry: ConfigEntry | None = None,
        delay_controller: LiveDelayController | None = None,
        live_state: LiveAvailabilityTracker | None = None,
        history_limit: int = 10,
    ) -> None:
        super().__init__(
            hass,
            coordinator_logger("pitstops", suppress_manual=True),
            name="F1 PitStop Coordinator",
            update_interval=None,
            config_entry=config_entry,
        )
        self._session = async_get_clientsession(hass)
        self._session_coord = session_coord
        self.available = True
        self._bus = bus
        self._config_entry = config_entry
        self._unsubs: list[Callable[[], None]] = []
        self._delay_listener: Optional[Callable[[], None]] = None
        self._delay = max(0, int(delay_seconds or 0))
        if delay_controller is not None:
            self._delay_listener = delay_controller.add_listener(self.set_delay)
        self._live_state_unsub: Optional[Callable[[], None]] = None
        if live_state is not None:
            self._live_state_unsub = live_state.add_listener(self._handle_live_state)

        self._session_unsub: Optional[Callable[[], None]] = None
        self._session_fingerprint: str | None = None

        self._history_limit = max(1, int(history_limit or 10))
        self._by_car: dict[str, list[dict]] = {}
        self._dedup: set[tuple] = set()
        self._driver_map: dict[str, dict[str, Any]] = {}
        self._deliver_handle: Optional[asyncio.Handle] = None

        self._state: dict[str, Any] = {
            "total_stops": 0,
            "cars": {},
            "last_update": None,
        }

    async def async_close(self, *_):
        for u in list(self._unsubs):
            try:
                u()
            except Exception:
                pass
        self._unsubs.clear()
        if self._deliver_handle:
            try:
                self._deliver_handle.cancel()
            except Exception:
                pass
            self._deliver_handle = None
        if self._delay_listener:
            try:
                self._delay_listener()
            except Exception:
                pass
            self._delay_listener = None
        if self._live_state_unsub:
            try:
                self._live_state_unsub()
            except Exception:
                pass
            self._live_state_unsub = None
        if self._session_unsub:
            try:
                self._session_unsub()
            except Exception:
                pass
            self._session_unsub = None

    async def _async_update_data(self):
        return self._state

    def _handle_live_state(self, is_live: bool, reason: str | None) -> None:
        if reason == "init":
            return
        self.available = is_live
        if not is_live:
            self._reset_store()

    def set_delay(self, seconds: int) -> None:
        new_delay = max(0, int(seconds or 0))
        if new_delay == self._delay:
            return
        self._delay = new_delay
        if self._deliver_handle:
            try:
                self._deliver_handle.cancel()
            except Exception:
                pass
            self._deliver_handle = None

    def _reset_store(self) -> None:
        self._by_car = {}
        self._dedup = set()
        self._state = {"total_stops": 0, "cars": {}, "last_update": None}
        try:
            self.async_set_updated_data(self._state)
        except Exception:
            pass

    @staticmethod
    def _parse_int(value: Any) -> int | None:
        try:
            if value is None:
                return None
            if isinstance(value, int):
                return value
            text = str(value).strip()
            if not text:
                return None
            if text.isdigit():
                return int(text)
            return int(float(text))
        except Exception:
            return None

    @staticmethod
    def _parse_float(value: Any) -> float | None:
        try:
            if value is None:
                return None
            if isinstance(value, (int, float)):
                return float(value)
            text = str(value).strip()
            if not text:
                return None
            return float(text)
        except Exception:
            return None

    @staticmethod
    def _compute_session_fingerprint(index_payload: Any) -> str | None:
        """Best-effort fingerprint used to reset between sessions/weekends."""
        if not isinstance(index_payload, dict):
            return None
        try:
            meetings = index_payload.get("Meetings") or index_payload.get("meetings")
            sessions = index_payload.get("Sessions") or index_payload.get("sessions")
            minimal = {"Meetings": meetings, "Sessions": sessions}
            return json.dumps(minimal, sort_keys=True, default=str)[:20000]
        except Exception:
            return None

    def _on_session_index_update(self) -> None:
        fp = self._compute_session_fingerprint(getattr(self._session_coord, "data", None))
        if fp is None:
            return
        if self._session_fingerprint is None:
            self._session_fingerprint = fp
            return
        if fp != self._session_fingerprint:
            self._session_fingerprint = fp
            self._reset_store()

    def _schedule_deliver(self) -> None:
        if self._delay > 0:
            try:
                if self._deliver_handle:
                    self._deliver_handle.cancel()
            except Exception:
                pass
            self._deliver_handle = self.hass.loop.call_later(self._delay, self._deliver)
        else:
            try:
                if self._deliver_handle:
                    self._deliver_handle.cancel()
            except Exception:
                pass
            self._deliver_handle = self.hass.loop.call_soon(self._deliver)

    def _add_stop(self, racing_number: str, stop: dict) -> None:
        rn = str(racing_number or "").strip()
        if not rn:
            return
        lap = self._parse_int(stop.get("lap"))
        ts = stop.get("timestamp")
        pit_stop_time = self._parse_float(stop.get("pit_stop_time"))
        pit_lane_time = self._parse_float(stop.get("pit_lane_time"))

        # Dedup: prefer timestamp when present, else fall back to lap/times.
        if ts:
            key = (rn, "ts", str(ts), pit_lane_time, pit_stop_time)
        else:
            key = (rn, "no_ts", lap, pit_lane_time, pit_stop_time)
        if key in self._dedup:
            return
        self._dedup.add(key)

        entry = {
            "lap": lap,
            "timestamp": str(ts) if ts else None,
            "pit_stop_time": pit_stop_time,
            "pit_lane_time": pit_lane_time,
        }
        lst = self._by_car.setdefault(rn, [])
        lst.append(entry)
        if len(lst) > self._history_limit:
            self._by_car[rn] = lst[-self._history_limit :]

    def _ingest_pitstopseries(self, msg: dict) -> None:
        pit_times = (msg or {}).get("PitTimes")
        if not isinstance(pit_times, dict):
            return
        for rn, entries in pit_times.items():
            if isinstance(entries, list):
                iterable = entries
            elif isinstance(entries, dict):
                iterable = list(entries.values())
            else:
                continue
            for item in iterable:
                if not isinstance(item, dict):
                    continue
                pitstop = item.get("PitStop")
                if not isinstance(pitstop, dict):
                    continue
                timestamp = item.get("Timestamp")
                self._add_stop(
                    str(pitstop.get("RacingNumber") or rn),
                    {
                        "lap": pitstop.get("Lap"),
                        "timestamp": timestamp,
                        "pit_stop_time": pitstop.get("PitStopTime"),
                        "pit_lane_time": pitstop.get("PitLaneTime"),
                    },
                )

    def _on_driverlist(self, payload: dict) -> None:
        """Merge DriverList into an rn -> {tla,name,team} mapping."""
        if not isinstance(payload, dict):
            return
        for rn, info in (payload or {}).items():
            if not isinstance(info, dict):
                continue
            racing_number = str(info.get("RacingNumber") or rn).strip()
            if not racing_number:
                continue
            self._driver_map[racing_number] = {
                "tla": info.get("Tla"),
                "name": info.get("FullName") or info.get("BroadcastName"),
                "team": info.get("TeamName"),
            }

    def _seed_driver_map_from_ergast(self) -> None:
        """Fallback identity mapping using Ergast/Jolpica driver standings.

        This is especially important in replay mode where only one stream dump
        (e.g. PitStopSeries) is replayed, meaning DriverList frames are absent.
        """
        try:
            if not self._config_entry:
                return
            reg = self.hass.data.get(DOMAIN, {}).get(self._config_entry.entry_id)
            if not isinstance(reg, dict):
                return
            driver_coord = reg.get("driver_coordinator")
            data = getattr(driver_coord, "data", None) or {}
            standings = (
                (data.get("MRData") or {})
                .get("StandingsTable", {})
                .get("StandingsLists", [])
            )
            if not isinstance(standings, list) or not standings:
                return
            ds = (standings[0] or {}).get("DriverStandings", [])
            if not isinstance(ds, list):
                return
            for item in ds:
                if not isinstance(item, dict):
                    continue
                driver = item.get("Driver") or {}
                if not isinstance(driver, dict):
                    continue
                rn = str(driver.get("permanentNumber") or "").strip()
                if not rn:
                    continue
                code = driver.get("code") or driver.get("driverId")
                given = driver.get("givenName")
                family = driver.get("familyName")
                name = None
                try:
                    parts = [p for p in (given, family) if p]
                    name = " ".join(parts) if parts else None
                except Exception:
                    name = None
                constructors = item.get("Constructors") or []
                team = None
                if isinstance(constructors, list) and constructors:
                    c0 = constructors[0]
                    if isinstance(c0, dict):
                        team = c0.get("name")
                # Do not overwrite non-null values from DriverList
                existing = self._driver_map.get(rn) if isinstance(self._driver_map, dict) else None
                if isinstance(existing, dict):
                    if existing.get("tla") or existing.get("name") or existing.get("team"):
                        continue
                self._driver_map[rn] = {"tla": code, "name": name, "team": team}
        except Exception:
            return

    def _on_bus_pitstopseries(self, msg: dict) -> None:
        if not isinstance(msg, dict):
            return
        self._ingest_pitstopseries(msg)
        self._schedule_deliver()

    def _deliver(self) -> None:
        self.available = True
        cars: dict[str, Any] = {}
        total = 0
        try:
            for rn, stops in sorted(
                self._by_car.items(),
                key=lambda kv: int(str(kv[0])) if str(kv[0]).isdigit() else str(kv[0]),
            ):
                lst = list(stops or [])
                ident = self._driver_map.get(str(rn), {}) if isinstance(self._driver_map, dict) else {}
                cars[str(rn)] = {
                    "tla": ident.get("tla"),
                    "name": ident.get("name"),
                    "team": ident.get("team"),
                    "count": len(lst),
                    "stops": lst,
                }
                total += len(lst)
        except Exception:
            cars = {
                str(rn): {"count": len(stops or []), "stops": list(stops or [])}
                for rn, stops in (self._by_car or {}).items()
            }
            try:
                total = sum(
                    v.get("count", 0) for v in cars.values() if isinstance(v, dict)
                )
            except Exception:
                total = 0

        self._state = {
            "total_stops": int(total),
            "cars": cars,
            "last_update": dt_util.utcnow().isoformat(timespec="seconds"),
        }
        self.async_set_updated_data(self._state)

    async def async_config_entry_first_refresh(self):
        await super().async_config_entry_first_refresh()
        # Seed identity mapping from Ergast/Jolpica so replay mode still shows TLA/name/team.
        self._seed_driver_map_from_ergast()
        # Reset when LiveTiming index changes (session/weekend rollover)
        try:
            self._session_fingerprint = self._compute_session_fingerprint(
                getattr(self._session_coord, "data", None)
            )
            self._session_unsub = self._session_coord.async_add_listener(
                self._on_session_index_update
            )
        except Exception:
            self._session_unsub = None
        # Subscribe to shared live bus streams
        bus = self._bus or self.hass.data.get(DOMAIN, {}).get("live_bus")
        try:
            self._unsubs.append(bus.subscribe("DriverList", self._on_driverlist))  # type: ignore[attr-defined]
        except Exception:
            pass
        try:
            self._unsubs.append(
                bus.subscribe("PitStopSeries", self._on_bus_pitstopseries)  # type: ignore[attr-defined]
            )
        except Exception:
            pass


class ChampionshipPredictionCoordinator(DataUpdateCoordinator):
    """Coordinator for ChampionshipPrediction updates using SignalR.

    Maintains merged state across incremental payloads:
        data = {
          "drivers": { rn: {...merged fields...}, ... },
          "teams": { team_key: {...merged fields...}, ... },
          "predicted_driver_p1": { "racing_number": str|None, "tla": str|None, "points": float|None, "entry": dict|None },
          "predicted_team_p1": { "team_key": str|None, "team_name": str|None, "points": float|None, "entry": dict|None },
          "last_update": ISO string,
        }
    """

    def __init__(
        self,
        hass: HomeAssistant,
        session_coord: "LiveSessionCoordinator",
        delay_seconds: int = 0,
        bus: LiveBus | None = None,
        config_entry: ConfigEntry | None = None,
        delay_controller: LiveDelayController | None = None,
        live_state: LiveAvailabilityTracker | None = None,
    ) -> None:
        super().__init__(
            hass,
            coordinator_logger("championship_prediction", suppress_manual=True),
            name="F1 Championship Prediction Coordinator",
            update_interval=None,
            config_entry=config_entry,
        )
        self._session = async_get_clientsession(hass)
        self._session_coord = session_coord
        self.available = True
        self._bus = bus
        self._config_entry = config_entry

        self._unsubs: list[Callable[[], None]] = []
        self._delay_listener: Optional[Callable[[], None]] = None
        self._delay = max(0, int(delay_seconds or 0))
        if delay_controller is not None:
            self._delay_listener = delay_controller.add_listener(self.set_delay)

        self._live_state_unsub: Optional[Callable[[], None]] = None
        if live_state is not None:
            self._live_state_unsub = live_state.add_listener(self._handle_live_state)

        self._session_unsub: Optional[Callable[[], None]] = None
        self._session_fingerprint: str | None = None

        self._drivers: dict[str, dict[str, Any]] = {}
        self._teams: dict[str, dict[str, Any]] = {}
        self._driver_map: dict[str, dict[str, Any]] = {}

        self._deliver_handle: Optional[asyncio.Handle] = None
        self._state: dict[str, Any] = {
            "drivers": {},
            "teams": {},
            "predicted_driver_p1": {
                "racing_number": None,
                "tla": None,
                "points": None,
                "entry": None,
            },
            "predicted_team_p1": {
                "team_key": None,
                "team_name": None,
                "points": None,
                "entry": None,
            },
            "last_update": None,
        }

    async def async_close(self, *_):
        for u in list(self._unsubs):
            try:
                u()
            except Exception:
                pass
        self._unsubs.clear()
        if self._deliver_handle:
            try:
                self._deliver_handle.cancel()
            except Exception:
                pass
            self._deliver_handle = None
        if self._delay_listener:
            try:
                self._delay_listener()
            except Exception:
                pass
            self._delay_listener = None
        if self._live_state_unsub:
            try:
                self._live_state_unsub()
            except Exception:
                pass
            self._live_state_unsub = None
        if self._session_unsub:
            try:
                self._session_unsub()
            except Exception:
                pass
            self._session_unsub = None

    async def _async_update_data(self):
        return self._state

    def _handle_live_state(self, is_live: bool, reason: str | None) -> None:
        if reason == "init":
            return
        self.available = is_live
        if not is_live:
            self._reset_store()

    def set_delay(self, seconds: int) -> None:
        new_delay = max(0, int(seconds or 0))
        if new_delay == self._delay:
            return
        self._delay = new_delay
        if self._deliver_handle:
            try:
                self._deliver_handle.cancel()
            except Exception:
                pass
            self._deliver_handle = None

    def _reset_store(self) -> None:
        self._drivers = {}
        self._teams = {}
        self._state = {
            "drivers": {},
            "teams": {},
            "predicted_driver_p1": {
                "racing_number": None,
                "tla": None,
                "points": None,
                "entry": None,
            },
            "predicted_team_p1": {
                "team_key": None,
                "team_name": None,
                "points": None,
                "entry": None,
            },
            "last_update": None,
        }
        try:
            self.async_set_updated_data(self._state)
        except Exception:
            pass

    @staticmethod
    def _compute_session_fingerprint(index_payload: Any) -> str | None:
        if not isinstance(index_payload, dict):
            return None
        try:
            meetings = index_payload.get("Meetings") or index_payload.get("meetings")
            sessions = index_payload.get("Sessions") or index_payload.get("sessions")
            minimal = {"Meetings": meetings, "Sessions": sessions}
            return json.dumps(minimal, sort_keys=True, default=str)[:20000]
        except Exception:
            return None

    def _on_session_index_update(self) -> None:
        fp = self._compute_session_fingerprint(getattr(self._session_coord, "data", None))
        if fp is None:
            return
        if self._session_fingerprint is None:
            self._session_fingerprint = fp
            return
        if fp != self._session_fingerprint:
            self._session_fingerprint = fp
            self._reset_store()

    def _schedule_deliver(self) -> None:
        if self._delay > 0:
            try:
                if self._deliver_handle:
                    self._deliver_handle.cancel()
            except Exception:
                pass
            self._deliver_handle = self.hass.loop.call_later(self._delay, self._deliver)
        else:
            try:
                if self._deliver_handle:
                    self._deliver_handle.cancel()
            except Exception:
                pass
            self._deliver_handle = self.hass.loop.call_soon(self._deliver)

    @staticmethod
    def _deep_merge(dst: dict[str, Any], src: dict[str, Any]) -> dict[str, Any]:
        """Shallow/deep merge dicts: nested dicts are merged recursively."""
        if not isinstance(dst, dict):
            dst = {}
        for k, v in (src or {}).items():
            if isinstance(v, dict) and isinstance(dst.get(k), dict):
                dst[k] = ChampionshipPredictionCoordinator._deep_merge(dst.get(k) or {}, v)
            else:
                dst[k] = v
        return dst

    def _ingest_prediction(self, msg: dict) -> None:
        if not isinstance(msg, dict):
            return
        drivers = msg.get("Drivers")
        if isinstance(drivers, dict):
            for key, patch in drivers.items():
                if not isinstance(patch, dict):
                    continue
                rn = str(patch.get("RacingNumber") or key).strip()
                if not rn:
                    continue
                cur = self._drivers.get(rn) or {}
                # Ensure RacingNumber is stable
                cur.setdefault("RacingNumber", rn)
                self._drivers[rn] = self._deep_merge(cur, patch)

        teams = msg.get("Teams")
        if isinstance(teams, dict):
            for team_key, patch in teams.items():
                if not isinstance(patch, dict):
                    continue
                tk = str(team_key).strip()
                if not tk:
                    continue
                cur = self._teams.get(tk) or {}
                cur.setdefault("TeamKey", tk)
                self._teams[tk] = self._deep_merge(cur, patch)

    def _on_driverlist(self, payload: dict) -> None:
        if not isinstance(payload, dict):
            return
        for rn, info in (payload or {}).items():
            if not isinstance(info, dict):
                continue
            racing_number = str(info.get("RacingNumber") or rn).strip()
            if not racing_number:
                continue
            self._driver_map[racing_number] = {
                "tla": info.get("Tla"),
                "name": info.get("FullName") or info.get("BroadcastName"),
                "team": info.get("TeamName"),
            }
        # identity update can change sensor state even without prediction deltas
        self._schedule_deliver()

    def _seed_driver_map_from_ergast(self) -> None:
        """Fallback identity mapping using Ergast/Jolpica driver standings (replay-friendly)."""
        try:
            if not self._config_entry:
                return
            reg = self.hass.data.get(DOMAIN, {}).get(self._config_entry.entry_id)
            if not isinstance(reg, dict):
                return
            driver_coord = reg.get("driver_coordinator")
            data = getattr(driver_coord, "data", None) or {}
            standings = (
                (data.get("MRData") or {})
                .get("StandingsTable", {})
                .get("StandingsLists", [])
            )
            if not isinstance(standings, list) or not standings:
                return
            ds = (standings[0] or {}).get("DriverStandings", [])
            if not isinstance(ds, list):
                return
            for item in ds:
                if not isinstance(item, dict):
                    continue
                driver = item.get("Driver") or {}
                if not isinstance(driver, dict):
                    continue
                rn = str(driver.get("permanentNumber") or "").strip()
                if not rn:
                    continue
                existing = self._driver_map.get(rn)
                if isinstance(existing, dict) and (existing.get("tla") or existing.get("name") or existing.get("team")):
                    continue
                code = driver.get("code") or driver.get("driverId")
                given = driver.get("givenName")
                family = driver.get("familyName")
                name = None
                try:
                    parts = [p for p in (given, family) if p]
                    name = " ".join(parts) if parts else None
                except Exception:
                    name = None
                constructors = item.get("Constructors") or []
                team = None
                if isinstance(constructors, list) and constructors:
                    c0 = constructors[0]
                    if isinstance(c0, dict):
                        team = c0.get("name")
                self._driver_map[rn] = {"tla": code, "name": name, "team": team}
        except Exception:
            return

    @staticmethod
    def _to_int(value: Any) -> int | None:
        try:
            if value is None:
                return None
            if isinstance(value, int):
                return value
            text = str(value).strip()
            if not text:
                return None
            if text.isdigit():
                return int(text)
            return int(float(text))
        except Exception:
            return None

    @staticmethod
    def _to_float(value: Any) -> float | None:
        try:
            if value is None:
                return None
            if isinstance(value, (int, float)):
                return float(value)
            text = str(value).strip()
            if not text:
                return None
            return float(text)
        except Exception:
            return None

    def _pick_predicted_driver_p1(self) -> tuple[str | None, dict | None]:
        best_rn = None
        best_entry = None
        best_pos = None
        for rn, entry in (self._drivers or {}).items():
            if not isinstance(entry, dict):
                continue
            pos = self._to_int(entry.get("PredictedPosition"))
            if pos is None:
                continue
            if best_pos is None or pos < best_pos:
                best_pos = pos
                best_rn = str(entry.get("RacingNumber") or rn)
                best_entry = entry
        return best_rn, best_entry

    def _pick_predicted_team_p1(self) -> tuple[str | None, dict | None]:
        best_key = None
        best_entry = None
        best_pos = None
        for key, entry in (self._teams or {}).items():
            if not isinstance(entry, dict):
                continue
            pos = self._to_int(entry.get("PredictedPosition"))
            if pos is None:
                continue
            if best_pos is None or pos < best_pos:
                best_pos = pos
                best_key = str(entry.get("TeamKey") or key)
                best_entry = entry
        return best_key, best_entry

    def _deliver(self) -> None:
        self.available = True

        p1_rn, p1_entry = self._pick_predicted_driver_p1()
        ident = self._driver_map.get(str(p1_rn), {}) if p1_rn else {}
        p1_tla = ident.get("tla") if isinstance(ident, dict) else None
        p1_pts = self._to_float((p1_entry or {}).get("PredictedPoints")) if isinstance(p1_entry, dict) else None

        t1_key, t1_entry = self._pick_predicted_team_p1()
        team_name = None
        if isinstance(t1_entry, dict):
            team_name = t1_entry.get("TeamName") or t1_entry.get("teamName")
        if not team_name and t1_key:
            team_name = str(t1_key)
        t1_pts = self._to_float((t1_entry or {}).get("PredictedPoints")) if isinstance(t1_entry, dict) else None

        self._state = {
            "drivers": dict(self._drivers),
            "teams": dict(self._teams),
            "predicted_driver_p1": {
                "racing_number": p1_rn,
                "tla": p1_tla,
                "points": p1_pts,
                "entry": dict(p1_entry) if isinstance(p1_entry, dict) else None,
            },
            "predicted_team_p1": {
                "team_key": t1_key,
                "team_name": team_name,
                "points": t1_pts,
                "entry": dict(t1_entry) if isinstance(t1_entry, dict) else None,
            },
            "last_update": dt_util.utcnow().isoformat(timespec="seconds"),
        }
        self.async_set_updated_data(self._state)

    def _on_bus_message(self, msg: dict) -> None:
        if not isinstance(msg, dict):
            return
        self._ingest_prediction(msg)
        self._schedule_deliver()

    async def async_config_entry_first_refresh(self):
        await super().async_config_entry_first_refresh()
        # Seed driver identity for replay mode (single-stream dump).
        self._seed_driver_map_from_ergast()
        # Reset on index/session rollover
        try:
            self._session_fingerprint = self._compute_session_fingerprint(
                getattr(self._session_coord, "data", None)
            )
            self._session_unsub = self._session_coord.async_add_listener(
                self._on_session_index_update
            )
        except Exception:
            self._session_unsub = None
        # Subscriptions
        bus = self._bus or self.hass.data.get(DOMAIN, {}).get("live_bus")
        try:
            self._unsubs.append(
                bus.subscribe("ChampionshipPrediction", self._on_bus_message)  # type: ignore[attr-defined]
            )
        except Exception:
            pass
        try:
            self._unsubs.append(
                bus.subscribe("DriverList", self._on_driverlist)  # type: ignore[attr-defined]
            )
        except Exception:
            pass

class LiveDriversCoordinator(DataUpdateCoordinator):
    """Coordinator aggregating DriverList, TimingData, TimingAppData, LapCount and SessionStatus.

    Exposes a consolidated structure suitable for sensors:
    data = {
      "drivers": {
         rn: {
            "identity": {"tla","name","team","team_color","racing_number"},
            "timing": {"position","gap_to_leader","interval","last_lap","best_lap","in_pit","retired","stopped","status_code"},
            "tyres": {"compound","stint_laps","new"},
            "laps": {"lap_current","lap_total"},
         },
      },
      "leader_rn": rn | None,
      "lap_current": int | None,
      "lap_total": int | None,
      "session_status": dict | None,
      "frozen": bool,
    }
    """

    def __init__(
        self,
        hass: HomeAssistant,
        session_coord: 'LiveSessionCoordinator',
        delay_seconds: int = 0,
        bus: LiveBus | None = None,
        config_entry: ConfigEntry | None = None,
        delay_controller: LiveDelayController | None = None,
        live_state: LiveAvailabilityTracker | None = None,
    ) -> None:
        super().__init__(
            hass,
            coordinator_logger("live_drivers", suppress_manual=True),
            name="F1 Live Drivers Coordinator",
            update_interval=None,
            config_entry=config_entry,
        )
        self._session = async_get_clientsession(hass)
        self._session_coord = session_coord
        self._deliver_handle: Optional[asyncio.Handle] = None
        self._bus = bus
        self._unsubs: list[Callable[[], None]] = []
        self._delay_listener: Optional[Callable[[], None]] = None
        self._delay = max(0, int(delay_seconds or 0))
        if delay_controller is not None:
            self._delay_listener = delay_controller.add_listener(self.set_delay)
        self.available = True
        self._state: dict[str, Any] = {
            "drivers": {},
            "leader_rn": None,
            "lap_current": None,
            "lap_total": None,
            "session_status": None,
            "frozen": False,
        }
        self._live_state_unsub: Optional[Callable[[], None]] = None
        if live_state is not None:
            self._live_state_unsub = live_state.add_listener(self._handle_live_state)

    async def async_close(self, *_):
        for u in list(self._unsubs):
            try:
                u()
            except Exception:
                pass
        self._unsubs.clear()
        if self._deliver_handle:
            try:
                self._deliver_handle.cancel()
            except Exception:
                pass
            self._deliver_handle = None
        if self._delay_listener:
            try:
                self._delay_listener()
            except Exception:
                pass
            self._delay_listener = None
        if self._live_state_unsub:
            try:
                self._live_state_unsub()
            except Exception:
                pass
            self._live_state_unsub = None

    async def _async_update_data(self):
        return self._state

    def _merge_driverlist(self, payload: dict) -> None:
        # payload: { rn: {Tla, FullName, TeamName, TeamColour, ...}, ... }
        drivers = self._state["drivers"]
        for rn, info in (payload or {}).items():
            if not isinstance(info, dict):
                continue
            # Derive headshot URLs in both small (transform) and large (original) forms
            headshot_raw = info.get("HeadshotUrl")
            headshot_small = headshot_raw if isinstance(headshot_raw, str) else None
            headshot_large = headshot_small
            try:
                if isinstance(headshot_raw, str):
                    idx = headshot_raw.find(".transform/")
                    if idx != -1:
                        headshot_large = headshot_raw[:idx]
            except Exception:
                headshot_large = headshot_small
            ident = drivers.setdefault(rn, {})
            ident.setdefault("identity", {})
            ident.setdefault("timing", {})
            ident.setdefault("tyres", {})
            ident.setdefault("laps", {})
            ident["identity"].update(
                {
                    "racing_number": str(info.get("RacingNumber") or rn),
                    "tla": info.get("Tla"),
                    "name": info.get("FullName") or info.get("BroadcastName"),
                    "team": info.get("TeamName"),
                    "team_color": info.get("TeamColour"),
                    "first_name": info.get("FirstName"),
                    "last_name": info.get("LastName"),
                    "headshot_small": headshot_small,
                    "headshot_large": headshot_large,
                    "reference": info.get("Reference"),
                }
            )

    @staticmethod
    def _get_value(d: dict | None, *path, default: Any = None):
        cur: Any = d
        for p in path:
            if not isinstance(cur, dict):
                return default
            cur = cur.get(p)
        return cur if cur is not None else default

    def _merge_timingdata(self, payload: dict) -> None:
        # payload: {"Lines": { rn: {...timing...} } }
        lines = (payload or {}).get("Lines", {})
        if not isinstance(lines, dict):
            return
        drivers = self._state["drivers"]
        # 1) Apply incremental updates to stored driver timing
        for rn, td in lines.items():
            if not isinstance(td, dict):
                continue
            entry = drivers.setdefault(rn, {})
            entry.setdefault("identity", {})
            entry.setdefault("timing", {})
            entry.setdefault("tyres", {})
            entry.setdefault("laps", {})
            timing = entry["timing"]
            # IMPORTANT: Only set fields that are present in this delta payload.
            if "Position" in td:
                pos_raw = td.get("Position")
                pos_str = str(pos_raw).strip() if pos_raw is not None else None
                timing["position"] = pos_str or None
            if "GapToLeader" in td:
                timing["gap_to_leader"] = td.get("GapToLeader")
            ival = self._get_value(td, "IntervalToPositionAhead", "Value")
            if ival is not None:
                timing["interval"] = ival
            last_lap = self._get_value(td, "LastLapTime", "Value")
            if last_lap is not None:
                timing["last_lap"] = last_lap
            best_lap = self._get_value(td, "BestLapTime", "Value")
            if best_lap is not None:
                timing["best_lap"] = best_lap
            if "InPit" in td:
                timing["in_pit"] = bool(td.get("InPit"))
            if "Retired" in td:
                timing["retired"] = bool(td.get("Retired"))
            if "Stopped" in td:
                timing["stopped"] = bool(td.get("Stopped"))
            if "Status" in td:
                timing["status_code"] = td.get("Status")
        # SessionPart (for Q1/Q2/Q3 detection)
        try:
            part = payload.get("SessionPart")
            if part is not None:
                self._state.setdefault("session", {})
                self._state["session"]["part"] = part
        except Exception:
            pass

    def set_delay(self, seconds: int) -> None:
        new_delay = max(0, int(seconds or 0))
        if new_delay == self._delay:
            return
        self._delay = new_delay
        if self._deliver_handle:
            try:
                self._deliver_handle.cancel()
            except Exception:
                pass
            self._deliver_handle = None

    def _handle_live_state(self, is_live: bool, reason: str | None) -> None:
        if reason == "init":
            return
        self.available = is_live
        if not is_live:
            # Clear consolidated state so a future session window does not briefly
            # show stale driver/timing information before the first live frames.
            try:
                self._state = {
                    "drivers": {},
                    "leader_rn": None,
                    "lap_current": None,
                    "lap_total": None,
                    "session_status": None,
                    "frozen": False,
                }
                self.async_set_updated_data(self._state)
            except Exception:
                pass
            return
        # 2) Recompute leader from full stored state (not just current delta)
        self._recompute_leader_from_state()

    def _recompute_leader_from_state(self) -> None:
        drivers = self._state.get("drivers", {}) or {}
        prev = self._state.get("leader_rn")
        # Prefer explicit position == "1"
        leader_rn = None
        for rn, info in drivers.items():
            pos = (info.get("timing", {}) or {}).get("position")
            if str(pos or "").strip() == "1":
                leader_rn = rn
                break
        if leader_rn is None:
            # Fallback: minimal numeric position across all stored drivers
            best: tuple[int, str] | None = None
            for rn, info in drivers.items():
                pos_str = str((info.get("timing", {}) or {}).get("position") or "").strip()
                try:
                    pos_int = int(pos_str) if pos_str.isdigit() else None
                except Exception:
                    pos_int = None
                if isinstance(pos_int, int):
                    if best is None or pos_int < best[0]:
                        best = (pos_int, rn)
            if best is not None:
                leader_rn = best[1]
        if leader_rn is None and prev:
            # If we cannot determine a leader from current positions, keep previous to avoid flapping
            leader_rn = prev
        if leader_rn is not None and leader_rn != prev:
            try:
                _LOGGER.debug("LiveDrivers: leader changed %s -> %s", prev, leader_rn)
            except Exception:
                pass
            self._state["leader_rn"] = leader_rn

    def _merge_timingapp(self, payload: dict) -> None:
        """Merge TimingAppData payloads.

        We now use the dedicated TyreStintSeries stream for tyre information, so this
        handler is only responsible for lap time fields from the embedded Stints.
        """
        # payload: {"Lines": { rn: {"Stints": { idx or list } } } }
        lines = (payload or {}).get("Lines", {})
        if not isinstance(lines, dict):
            return
        drivers = self._state["drivers"]
        for rn, app in lines.items():
            if not isinstance(app, dict):
                continue
            entry = drivers.setdefault(rn, {})
            entry.setdefault("timing", {})
            stints = app.get("Stints")
            latest: dict | None = None
            if isinstance(stints, list) and stints:
                latest = stints[-1] if isinstance(stints[-1], dict) else None
            elif isinstance(stints, dict) and stints:
                # Often indexed by numeric keys or 0/1
                try:
                    keys = [int(k) for k in stints.keys() if str(k).isdigit()]
                    if keys:
                        latest = stints.get(str(max(keys)))
                except Exception:
                    # Fallback: try key '0'
                    latest = stints.get("0") if isinstance(stints.get("0"), dict) else None
            if isinstance(latest, dict):
                # Lap times: map latest LapTime to timing.last_lap and update best_lap
                lap_time = latest.get("LapTime")
                if isinstance(lap_time, str) and lap_time:
                    timing = entry.setdefault("timing", {})
                    timing["last_lap"] = lap_time
                    prev_best = timing.get("best_lap")
                    try:
                        new_secs = self._parse_laptime_secs(lap_time)
                        prev_secs = self._parse_laptime_secs(prev_best) if isinstance(prev_best, str) else None
                        if new_secs is not None and (prev_secs is None or new_secs < prev_secs):
                            timing["best_lap"] = lap_time
                    except Exception:
                        # If parsing fails, at least keep last_lap updated
                        pass
        # Lap time changes sometimes coincide with leader changes
        self._recompute_leader_from_state()

    def _merge_tyre_stints(self, payload: dict) -> None:
        """Merge TyreStintSeries payloads into per-driver tyre state.

        Expected payload shape (from SignalR stream \"TyreStintSeries\"):
            {"Stints": { rn: { idx: {Compound, New, TotalLaps, ...}, ... }, ... }}
        """
        stints_root = (payload or {}).get("Stints", {})
        if not isinstance(stints_root, dict):
            return
        drivers = self._state["drivers"]
        for rn, stints in stints_root.items():
            if not isinstance(stints, (dict, list)):
                continue
            entry = drivers.setdefault(rn, {})
            entry.setdefault("tyres", {})
            tyres = entry["tyres"]
            latest: dict | None = None
            if isinstance(stints, list) and stints:
                latest = stints[-1] if isinstance(stints[-1], dict) else None
            elif isinstance(stints, dict) and stints:
                try:
                    keys = [int(k) for k in stints.keys() if str(k).isdigit()]
                    if keys:
                        latest = stints.get(str(max(keys)))
                except Exception:
                    latest = stints.get("0") if isinstance(stints.get("0"), dict) else None
            if not isinstance(latest, dict):
                continue

            # Only overwrite fields that are present in this delta to avoid losing
            # previously-known compound/new values when we receive TotalLaps-only frames.
            if "Compound" in latest:
                tyres["compound"] = latest.get("Compound")
            if "TotalLaps" in latest:
                stint_laps = latest.get("TotalLaps")
                tyres["stint_laps"] = (
                    int(stint_laps) if str(stint_laps or "").isdigit() else stint_laps
                )
            if "New" in latest:
                is_new = latest.get("New")
                s = str(is_new).lower()
                if s == "true":
                    tyres["new"] = True
                elif s == "false":
                    tyres["new"] = False
                else:
                    tyres["new"] = is_new

        # Tyre changes can also interact with leader logic (pit stops etc.)
        self._recompute_leader_from_state()

    def _merge_lapcount(self, payload: dict) -> None:
        # payload may be either {CurrentLap, TotalLaps} or wrapped
        curr = payload.get("CurrentLap") or payload.get("LapCount")
        total = payload.get("TotalLaps")
        try:
            curr_i = int(curr) if curr is not None else None
        except Exception:
            curr_i = None
        try:
            total_i = int(total) if total is not None else None
        except Exception:
            total_i = None
        self._state["lap_current"] = curr_i
        self._state["lap_total"] = total_i
        # Mirror into each driver for convenience
        for entry in self._state["drivers"].values():
            entry.setdefault("laps", {})
            entry["laps"].update({"lap_current": curr_i, "lap_total": total_i})
        # Recompute leader as lap and position updates can interact
        self._recompute_leader_from_state()

    @staticmethod
    def _parse_laptime_secs(value: str | None) -> float | None:
        """Parse a lap time formatted like 'M:SS.mmm' or 'SS.mmm' to seconds."""
        if not value:
            return None
        try:
            s = value.strip()
            if ":" in s:
                minutes_str, sec_str = s.split(":", 1)
                minutes = int(minutes_str)
                seconds = float(sec_str)
                return minutes * 60.0 + seconds
            return float(s)
        except Exception:
            return None

    def _merge_sessionstatus(self, payload: dict) -> None:
        self._state["session_status"] = payload
        try:
            msg = str(payload.get("Status") or payload.get("Message") or "").strip()
            started_flag = payload.get("Started")
            # Freeze at session end
            if msg in ("Finished", "Finalised", "Ends"):
                self._state["frozen"] = True
            # Unfreeze on new session start or green running
            elif started_flag is True or msg in ("Started", "Green", "GreenFlag"):
                self._state["frozen"] = False
        except Exception:
            pass

    def set_delay(self, seconds: int) -> None:
        new_delay = max(0, int(seconds or 0))
        if new_delay == self._delay:
            return
        self._delay = new_delay
        if self._deliver_handle:
            try:
                self._deliver_handle.cancel()
            except Exception:
                pass
            self._deliver_handle = None

    @staticmethod
    def _extract(data: dict, key: str) -> dict | None:
        if not isinstance(data, dict):
            return None
        messages = data.get("M")
        if isinstance(messages, list):
            for update in messages:
                args = update.get("A", [])
                if len(args) >= 2 and args[0] == key:
                    return args[1]
        result = data.get("R")
        if isinstance(result, dict) and key in result:
            return result.get(key)
        return None

    def _deliver(self) -> None:
        # Push deep-copied shallow dict to avoid accidental external mutation
        self.async_set_updated_data(self._state)

    def _schedule_deliver(self) -> None:
        if self._delay > 0:
            try:
                if self._deliver_handle:
                    self._deliver_handle.cancel()
            except Exception:
                pass
            self._deliver_handle = self.hass.loop.call_later(self._delay, self._deliver)
        else:
            try:
                if self._deliver_handle:
                    self._deliver_handle.cancel()
            except Exception:
                pass
            self._deliver_handle = self.hass.loop.call_soon(self._deliver)

    def _on_driverlist(self, dl: dict) -> None:
        # Allow DriverList merges even when frozen so identity mapping remains available
        self._merge_driverlist(dl)
        self._schedule_deliver()

    def _on_timingdata(self, td: dict) -> None:
        if self._state.get("frozen"):
            return
        self._merge_timingdata(td)
        self._schedule_deliver()

    def _on_timingapp(self, ta: dict) -> None:
        if self._state.get("frozen"):
            return
        self._merge_timingapp(ta)
        self._schedule_deliver()

    def _on_tyre_stints(self, ts: dict) -> None:
        if self._state.get("frozen"):
            return
        self._merge_tyre_stints(ts)
        self._schedule_deliver()

    def _on_lapcount(self, lc: dict) -> None:
        if self._state.get("frozen"):
            return
        self._merge_lapcount(lc)
        self._schedule_deliver()

    def _on_sessionstatus(self, ss: dict) -> None:
        # Always process SessionStatus so we can transition out of frozen on new sessions
        self._merge_sessionstatus(ss)
        self._schedule_deliver()

    async def async_config_entry_first_refresh(self):
        await super().async_config_entry_first_refresh()
        # Subscribe to LiveBus streams
        try:
            bus = (self._bus or self.hass.data.get(DOMAIN, {}).get("live_bus"))  # type: ignore[assignment]
        except Exception:
            bus = None
        if bus is not None:
            try:
                self._unsubs.append(bus.subscribe("DriverList", self._on_driverlist))
            except Exception:
                pass
            try:
                self._unsubs.append(bus.subscribe("TimingData", self._on_timingdata))
            except Exception:
                pass
            try:
                self._unsubs.append(bus.subscribe("TimingAppData", self._on_timingapp))
            except Exception:
                pass
            try:
                self._unsubs.append(bus.subscribe("TyreStintSeries", self._on_tyre_stints))
            except Exception:
                pass
            try:
                self._unsubs.append(bus.subscribe("LapCount", self._on_lapcount))
            except Exception:
                pass
            try:
                self._unsubs.append(bus.subscribe("SessionStatus", self._on_sessionstatus))
            except Exception:
                pass

    def set_delay(self, seconds: int) -> None:
        new_delay = max(0, int(seconds or 0))
        if new_delay == self._delay:
            return
        self._delay = new_delay
        if self._deliver_handle:
            try:
                self._deliver_handle.cancel()
            except Exception:
                pass
            self._deliver_handle = None


async def async_unload_entry(hass: HomeAssistant, entry: ConfigEntry) -> bool:
    unload_ok = await hass.config_entries.async_unload_platforms(entry, PLATFORMS)
    # Proceed with best-effort cleanup even if unload_ok is False, but keep return value
    try:
        data_root = hass.data.get(DOMAIN)
        data = None
        if isinstance(data_root, dict):
            data = data_root.pop(entry.entry_id, None)
        if isinstance(data, dict):
            for name, obj in list(data.items()):
                if obj is None:
                    continue
                close = getattr(obj, "async_close", None)
                if callable(close):
                    try:
                        await close()
                    except Exception as err:  # noqa: BLE001
                        _LOGGER.debug("Error during %s async_close: %s", name, err)
        # If this was the last entry, remove dev-only stats reporter.
        if isinstance(data_root, dict):
            # Keep only real entry dicts (exclude our global stats key)
            remaining_entries = [
                k for k in data_root.keys() if isinstance(k, str) and k != _JOLPICA_STATS_KEY
            ]
            if not remaining_entries:
                stats = data_root.get(_JOLPICA_STATS_KEY)
                unsub = stats.get("unsub") if isinstance(stats, dict) else None
                if callable(unsub):
                    try:
                        unsub()
                    except Exception:
                        pass
                data_root.pop(_JOLPICA_STATS_KEY, None)
    except Exception as err:  # noqa: BLE001
        _LOGGER.debug("Error during entry data cleanup: %s", err)
    return unload_ok


    


class F1DataCoordinator(DataUpdateCoordinator):
    """Handles updates from a given F1 endpoint."""

    def __init__(self, hass: HomeAssistant, url: str, name: str, session=None, user_agent: str | None = None, cache=None, inflight=None, ttl_seconds: int = 30, persist_map=None, persist_save=None, config_entry: ConfigEntry | None = None):
        super().__init__(
            hass,
            _LOGGER,
            name=name,
            update_interval=timedelta(hours=1),
            config_entry=config_entry,
        )
        self._session = session or async_get_clientsession(hass)
        self._headers = {"User-Agent": str(user_agent)} if user_agent else None
        self._url = url
        self._cache = cache
        self._inflight = inflight
        self._ttl = int(ttl_seconds or 30)
        self._persist = persist_map
        self._persist_save = persist_save
        self._last_seen_season: str | None = None

        # Initialize last-seen season from persisted current.json payload if present.
        # This makes rollover detection work immediately after a restart, even if the
        # first read is served from cache before the first network MISS.
        try:
            if self._url == API_URL and isinstance(self._persist, dict):
                rec = self._persist.get(API_URL)
                payload = rec.get("data") if isinstance(rec, dict) else None
                season = self._extract_season(payload) if payload else None
                if season:
                    self._last_seen_season = season
        except Exception:
            pass

    def _extract_season(self, payload: Any) -> str | None:
        """Best-effort extraction of season (year) from Ergast/Jolpica payloads."""
        try:
            mr = (payload or {}).get("MRData", {}) if isinstance(payload, dict) else {}
            rt = mr.get("RaceTable", {}) if isinstance(mr, dict) else {}
            season = rt.get("season")
            if season is not None:
                s = str(season).strip()
                return s if s else None
            # Fallback: infer from first race if available
            races = rt.get("Races") if isinstance(rt, dict) else None
            if isinstance(races, list) and races:
                season2 = races[0].get("season")
                if season2 is not None:
                    s2 = str(season2).strip()
                    return s2 if s2 else None
        except Exception:
            return None
        return None

    def _handle_season_rollover_if_needed(self, payload: Any) -> None:
        """If current season changed, invalidate cached /current/* endpoints and refresh dependents.

        This avoids keeping last year's 'current' data for weeks due to aggressive TTLs.
        """
        if self._url != API_URL:
            return
        season = self._extract_season(payload)
        if not season:
            return
        if self._last_seen_season is None:
            self._last_seen_season = season
            return
        if season == self._last_seen_season:
            return

        prev = self._last_seen_season
        self._last_seen_season = season
        _LOGGER.info("Detected season rollover %s -> %s; invalidating Jolpica /current cache", prev, season)

        # Invalidate in-memory cache entries for /current endpoints
        try:
            if isinstance(self._cache, dict):
                for k in list(self._cache.keys()):
                    ks = str(k)
                    if "/ergast/f1/current" in ks:
                        self._cache.pop(k, None)
        except Exception:
            pass

        # Invalidate persisted cache too, so restarts don't re-seed stale 'current' data
        try:
            if isinstance(self._persist, dict):
                for k in list(self._persist.keys()):
                    ks = str(k)
                    if "/ergast/f1/current" in ks:
                        self._persist.pop(k, None)
                if callable(self._persist_save):
                    self._persist_save()
        except Exception:
            pass

        # Trigger refresh of dependent coordinators for this entry (best effort)
        try:
            ce = getattr(self, "config_entry", None)
            entry_id = getattr(ce, "entry_id", None) if ce is not None else None
            if not entry_id:
                return
            reg = (self.hass.data.get(DOMAIN, {}) or {}).get(entry_id, {}) or {}
            for name in (
                "driver_coordinator",
                "constructor_coordinator",
                "last_race_coordinator",
                "season_results_coordinator",
                "sprint_results_coordinator",
            ):
                coord = reg.get(name)
                if coord is None:
                    continue
                req = getattr(coord, "async_request_refresh", None)
                if callable(req):
                    self.hass.async_create_task(req())
        except Exception:
            pass

    async def async_close(self, *_):
        """Placeholder for future cleanup."""
        return

    async def _async_update_data(self):
        """Fetch data from the F1 API."""
        try:
            async with async_timeout.timeout(10):
                data = await fetch_json(
                    self.hass,
                    self._session,
                    self._url,
                    headers=self._headers,
                    ttl_seconds=self._ttl,
                    cache=self._cache,
                    inflight=self._inflight,
                    persist_map=self._persist,
                    persist_save=self._persist_save,
                )
                # Detect season rollovers in current.json and clear stale caches if needed.
                self._handle_season_rollover_if_needed(data)
                return data
        except Exception as err:
            raise UpdateFailed(f"Error fetching data: {err}") from err


class F1SeasonResultsCoordinator(DataUpdateCoordinator):
    """Fetch all season results across paginated Ergast responses."""

    def __init__(
        self,
        hass: HomeAssistant,
        url: str,
        name: str,
        session=None,
        user_agent: str | None = None,
        cache=None,
        inflight=None,
        ttl_seconds: int = 6 * 3600,
        *,
        ttl_stable: int | None = None,
        ttl_recent: int | None = None,
        ttl_latest: int | None = None,
        persist_map=None,
        persist_save=None,
        config_entry: ConfigEntry | None = None,
        season_source: DataUpdateCoordinator | None = None,
    ):
        super().__init__(
            hass,
            _LOGGER,
            name=name,
            update_interval=timedelta(hours=1),
            config_entry=config_entry,
        )
        self._session = session or async_get_clientsession(hass)
        self._headers = {"User-Agent": str(user_agent)} if user_agent else None
        self._base_url = url
        self._cache = cache
        self._inflight = inflight
        # ttl_seconds acts as a backward-compatible default (treated as "latest").
        default_latest = int(ttl_seconds or 6 * 3600)
        self._ttl_latest = int(ttl_latest or default_latest)
        self._ttl_recent = int(ttl_recent or max(6 * 3600, 24 * 3600))
        self._ttl_stable = int(ttl_stable or 30 * 24 * 3600)
        self._persist = persist_map
        self._persist_save = persist_save
        self._season_source = season_source

    async def async_close(self, *_):
        return

    @staticmethod
    def _extract_season(payload: Any) -> str | None:
        """Best-effort extraction of season (year) from Ergast/Jolpica payloads."""
        try:
            if not isinstance(payload, dict):
                return None
            mr = payload.get("MRData", {}) or {}
            rt = mr.get("RaceTable", {}) or {}
            season = rt.get("season")
            if season is not None:
                s = str(season).strip()
                return s if s else None
            races = rt.get("Races")
            if isinstance(races, list) and races:
                season2 = (races[0] or {}).get("season")
                if season2 is not None:
                    s2 = str(season2).strip()
                    return s2 if s2 else None
        except Exception:
            return None
        return None

    def _effective_base_url(self) -> str:
        """Prefer a season-scoped URL (/f1/<year>/...) over /f1/current/... when possible.

        This avoids stale caches across season rollovers where /current endpoints keep the
        same URL, but the "meaning" changes.
        """
        base = str(self._base_url)
        src = getattr(self._season_source, "data", None) if self._season_source is not None else None
        season = self._extract_season(src)
        if not season:
            return base
        # Only rewrite known /current/ Ergast paths.
        marker = "/ergast/f1/current/"
        if marker in base:
            return base.replace(marker, f"/ergast/f1/{season}/")
        return base

    def _ttl_for_offset(self, offset: int, last_offset: int, page_size: int) -> int:
        """Return TTL for a given results page offset.

        - Stable pages (older part of season): very long TTL.
        - Recent pages: daily.
        - Latest page: every few hours.
        """
        try:
            o = int(offset)
            last = int(last_offset)
            size = max(1, int(page_size))
        except Exception:
            return self._ttl_latest
        if last <= 0:
            return self._ttl_latest
        if o >= last:
            return self._ttl_latest
        if o >= max(0, last - size):
            return self._ttl_recent
        return self._ttl_stable

    async def _fetch_page(self, limit: int, offset: int, *, ttl_seconds: int | None = None):
        from yarl import URL
        ttl = int(ttl_seconds or self._ttl_latest)

        # Primary: season-scoped URL when we can derive season from current.json.
        primary_base = self._effective_base_url()
        primary_url = str(URL(primary_base).with_query({"limit": str(limit), "offset": str(offset)}))

        async with async_timeout.timeout(10):
            try:
                return await fetch_json(
                    self.hass,
                    self._session,
                    primary_url,
                    headers=self._headers,
                    ttl_seconds=ttl,
                    cache=self._cache,
                    inflight=self._inflight,
                    persist_map=self._persist,
                    persist_save=self._persist_save,
                )
            except Exception:
                # Fallback: legacy /current/ URL (in case the API doesn't support season-scoped paths)
                fallback_url = str(URL(str(self._base_url)).with_query({"limit": str(limit), "offset": str(offset)}))
                if fallback_url == primary_url:
                    raise
                return await fetch_json(
                    self.hass,
                    self._session,
                    fallback_url,
                    headers=self._headers,
                    ttl_seconds=ttl,
                    cache=self._cache,
                    inflight=self._inflight,
                    persist_map=self._persist,
                    persist_save=self._persist_save,
                )

    @staticmethod
    def _race_key(r: dict) -> tuple:
        season = r.get("season")
        round_ = r.get("round")
        return (str(season) if season is not None else "", str(round_) if round_ is not None else "")

    async def _async_update_data(self):
        try:
            # Start with a large page size; use API-returned limit/offset/total for correctness
            request_limit = 200
            offset = 0

            races_by_key: dict[tuple, dict] = {}
            order: list[tuple] = []

            def merge_page(page_races: list[dict]):
                for race in page_races or []:
                    key = self._race_key(race)
                    existing = races_by_key.get(key)
                    if not existing:
                        copy = dict(race)
                        copy["Results"] = list(race.get("Results", []) or [])
                        races_by_key[key] = copy
                        order.append(key)
                    else:
                        seen = {
                            (res.get("Driver", {}).get("driverId"), res.get("position"))
                            for res in existing.get("Results", [])
                        }
                        for res in race.get("Results", []) or []:
                            ident = (res.get("Driver", {}).get("driverId"), res.get("position"))
                            if ident not in seen:
                                existing["Results"].append(res)
                                seen.add(ident)

            # Fetch first page (use recent TTL; we'll apply more specific TTLs
            # for additional pages once we know the total/last offset).
            first = await self._fetch_page(request_limit, offset, ttl_seconds=self._ttl_recent)
            mr = (first or {}).get("MRData", {})
            total = int((mr.get("total") or "0"))
            limit_used = int((mr.get("limit") or request_limit))
            offset_used = int((mr.get("offset") or offset))

            merge_page(((mr.get("RaceTable", {}) or {}).get("Races", []) or []))

            # Determine last page offset for TTL selection
            try:
                last_page_offset = ((max(0, total - 1) // max(1, limit_used)) * max(1, limit_used))
            except Exception:
                last_page_offset = offset_used

            # Iterate deterministically using server-reported paging
            next_offset = offset_used + limit_used
            # Cap loop iterations defensively
            safety = 0
            while next_offset < total and safety < 50:
                page_ttl = self._ttl_for_offset(next_offset, last_page_offset, limit_used)
                page = await self._fetch_page(limit_used, next_offset, ttl_seconds=page_ttl)
                pmr = (page or {}).get("MRData", {})
                praces = (pmr.get("RaceTable", {}) or {}).get("Races", []) or []
                merge_page(praces)
                try:
                    limit_used = int(pmr.get("limit") or limit_used)
                    offset_used = int(pmr.get("offset") or next_offset)
                    total = int(pmr.get("total") or total)
                except Exception:
                    pass
                next_offset = offset_used + limit_used
                safety += 1

            # Assemble and sort by season then numeric round
            assembled_races = [races_by_key[k] for k in order]
            assembled_races.sort(key=lambda r: (str(r.get("season")), int(str(r.get("round") or 0))))
            return {
                "MRData": {
                    "RaceTable": {
                        "Races": assembled_races,
                    }
                }
            }
        except Exception as err:
            raise UpdateFailed(f"Error fetching season results: {err}") from err


class F1SprintResultsCoordinator(DataUpdateCoordinator):
    """Fetch sprint results for the current season (single, non-paginated endpoint)."""

    def __init__(self, hass: HomeAssistant, url: str, name: str, session=None, user_agent: str | None = None, cache=None, inflight=None, ttl_seconds: int = 60, persist_map=None, persist_save=None, config_entry: ConfigEntry | None = None):
        super().__init__(
            hass,
            _LOGGER,
            name=name,
            update_interval=timedelta(hours=1),
            config_entry=config_entry,
        )
        self._session = session or async_get_clientsession(hass)
        self._headers = {"User-Agent": str(user_agent)} if user_agent else None
        self._url = url
        self._cache = cache
        self._inflight = inflight
        self._ttl = int(ttl_seconds or 60)
        self._persist = persist_map
        self._persist_save = persist_save

    async def async_close(self, *_):
        return

    async def _async_update_data(self):
        try:
            async with async_timeout.timeout(10):
                return await fetch_json(
                    self.hass,
                    self._session,
                    self._url,
                    headers=self._headers,
                    ttl_seconds=self._ttl,
                    cache=self._cache,
                    inflight=self._inflight,
                    persist_map=self._persist,
                    persist_save=self._persist_save,
                )
        except Exception as err:
            raise UpdateFailed(f"Error fetching sprint results: {err}") from err


class FiaDocumentsCoordinator(DataUpdateCoordinator):
    """Coordinator that scrapes FIA decision documents for the active race weekend."""

    def __init__(
        self,
        hass: HomeAssistant,
        race_coordinator: DataUpdateCoordinator,
        *,
        session=None,
        cache=None,
        inflight=None,
        ttl_seconds: int = FIA_DOCS_POLL_INTERVAL,
        persist_map=None,
        persist_save=None,
        config_entry: ConfigEntry | None = None,
    ):
        super().__init__(
            hass,
            _LOGGER,
            name="FIA Documents Coordinator",
            update_interval=timedelta(seconds=max(60, int(ttl_seconds or FIA_DOCS_POLL_INTERVAL))),
            config_entry=config_entry,
        )
        self._session = session or async_get_clientsession(hass)
        self._race_coordinator = race_coordinator
        self._cache = cache
        self._inflight = inflight
        self._ttl = max(60, int(ttl_seconds or FIA_DOCS_POLL_INTERVAL))
        self._persist = persist_map
        self._persist_save = persist_save
        self._season_url_cache: dict[str, str] = {}

    async def async_close(self, *_):
        return

    async def _async_update_data(self):
        race = self._get_next_race()
        if not race:
            return {"event_key": None, "race": None, "documents": []}

        season = str(race.get("season") or datetime.utcnow().year)
        round_ = str(race.get("round") or "")
        event_key = f"{season}_{round_ or 'next'}"

        season_url = await self._get_season_url(season)

        try:
            async with async_timeout.timeout(FIA_DOCS_FETCH_TIMEOUT):
                html = await fetch_text(
                    self.hass,
                    self._session,
                    season_url,
                    ttl_seconds=self._ttl,
                    cache=self._cache,
                    inflight=self._inflight,
                    persist_map=self._persist,
                    persist_save=self._persist_save,
                )
        except Exception as err:  # noqa: BLE001
            raise UpdateFailed(f"Error fetching FIA documents: {err}") from err

        try:
            docs = parse_fia_documents(html)
        except Exception as err:  # noqa: BLE001
            raise UpdateFailed(f"Error parsing FIA documents: {err}") from err

        return {
            "event_key": event_key,
            "race": self._summarize_race(race),
            "documents": docs,
        }

    async def _get_season_url(self, season: str) -> str:
        cached = self._season_url_cache.get(season)
        if cached:
            return cached
        slug = None
        try:
            async with async_timeout.timeout(FIA_DOCS_FETCH_TIMEOUT):
                html = await fetch_text(
                    self.hass,
                    self._session,
                    FIA_SEASON_LIST_URL,
                    ttl_seconds=self._ttl,
                    cache=self._cache,
                    inflight=self._inflight,
                    persist_map=self._persist,
                    persist_save=self._persist_save,
                )
            slug = self._extract_season_slug(html, season)
        except Exception as err:  # noqa: BLE001
            _LOGGER.debug("Failed to resolve FIA season slug for %s: %s", season, err)
        url = (
            urljoin(FIA_DOCUMENTS_BASE_URL + "/", slug)
            if slug
            else FIA_SEASON_FALLBACK_URL
        )
        self._season_url_cache[season] = url
        return url

    @staticmethod
    def _extract_season_slug(html: str, season: str) -> str | None:
        if not isinstance(html, str) or not html:
            return None
        pattern = re.compile(
            rf'href="(?P<href>/documents[^"]*season/season-{re.escape(str(season))}-\d+)"',
            re.IGNORECASE,
        )
        match = pattern.search(html)
        if match:
            return match.group("href")
        return None

    def _summarize_race(self, race: dict | None) -> dict:
        if not isinstance(race, dict):
            return {}
        circuit = race.get("Circuit", {}) or {}
        location = circuit.get("Location", {}) or {}
        return {
            "season": race.get("season"),
            "round": race.get("round"),
            "race_name": race.get("raceName"),
            "race_date": race.get("date"),
            "race_time": race.get("time"),
            "circuit_id": circuit.get("circuitId"),
            "circuit_name": circuit.get("circuitName"),
            "circuit_url": circuit.get("url"),
            "locality": location.get("locality"),
            "country": location.get("country"),
        }

    def _get_next_race(self) -> dict | None:
        data = getattr(self._race_coordinator, "data", None) or {}
        races = (data.get("MRData") or {}).get("RaceTable", {}).get("Races", [])
        if not isinstance(races, list):
            return None
        now = datetime.utcnow().replace(tzinfo=None)
        for race in races:
            date = race.get("date")
            time_str = race.get("time") or "00:00:00Z"
            dt_str = f"{date}T{time_str}".replace("Z", "+00:00")
            try:
                dt = datetime.fromisoformat(dt_str)
            except Exception:
                continue
            # Treat a race as ongoing for a grace period after the scheduled
            # start time so that "next race" style helpers don't jump ahead
            # too early.
            end_dt = dt + RACE_SWITCH_GRACE
            if end_dt.replace(tzinfo=None) > now:
                return race
        return races[-1] if races else None
class LiveSessionCoordinator(DataUpdateCoordinator):
    """Fetch current or next session from the LiveTiming index."""

    def __init__(self, hass: HomeAssistant, year: int, session=None, config_entry: ConfigEntry | None = None):
        super().__init__(
            hass,
            _LOGGER,
            name="F1 Live Session Coordinator",
            update_interval=timedelta(hours=1),
            config_entry=config_entry,
        )
        self._session = session or async_get_clientsession(hass)
        self.year = year
        self._last_good_index: dict | None = None
        # Expose last HTTP status so the live window supervisor can distinguish
        # "index not published yet" (403/404) from other failures.
        self.last_http_status: int | None = None
        self._log_throttle: dict[str, float] = {}

    def _log_throttled(
        self,
        level: int,
        key: str,
        msg: str,
        *args,
        interval_seconds: float = 3600,
    ) -> None:
        now = time.monotonic()
        last = self._log_throttle.get(key, 0.0)
        if now - last < interval_seconds:
            return
        self._log_throttle[key] = now
        _LOGGER.log(level, msg, *args)

    async def async_close(self, *_):
        return

    async def _async_update_data(self):
        payload = await self._fetch_index()
        if payload:
            self._last_good_index = payload
            return payload
        if self._last_good_index:
            # Avoid flooding logs if callers are forcing frequent refreshes.
            self._log_throttled(
                logging.DEBUG,
                "using_cached_index",
                "Using cached LiveTiming index (server returned empty response)",
                interval_seconds=3600,
            )
            return self._last_good_index
        return payload

    async def _fetch_index(self, *, cache_bust: bool = False):
        url = LIVETIMING_INDEX_URL.format(year=self.year)
        if cache_bust:
            url = f"{url}?t={int(time.time())}"
        try:
            async with async_timeout.timeout(10):
                async with self._session.get(url) as response:
                    text = await response.text()
                    self.last_http_status = response.status
                    if response.status != 200:
                        preview = text[:200]
                        # 403/404 is common when a new season index isn't published yet.
                        if response.status in (403, 404):
                            self._log_throttled(
                                logging.INFO,
                                f"index_http_{response.status}_{self.year}",
                                "LiveTiming index not available for year %s yet (HTTP %s). Will retry later.",
                                self.year,
                                response.status,
                                interval_seconds=6 * 3600,
                            )
                            _LOGGER.debug("Index fetch failed (%s): %s", response.status, preview)
                        else:
                            self._log_throttled(
                                logging.WARNING,
                                f"index_http_{response.status}_{self.year}",
                                "Index fetch failed (%s): %s",
                                response.status,
                                preview,
                                interval_seconds=3600,
                            )
                        return None
                    payload = json.loads(text.lstrip("\ufeff") or "null")
        except Exception as err:
            self._log_throttled(
                logging.WARNING,
                f"index_fetch_exception_{self.year}",
                "Error fetching index (%s): %s",
                "cache-bust" if cache_bust else "standard",
                err,
                interval_seconds=1800,
            )
            return None
        if self._has_sessions(payload):
            return payload
        if not cache_bust:
            _LOGGER.debug("Index response missing sessions; retrying with cache-buster")
            return await self._fetch_index(cache_bust=True)
        self._log_throttled(
            logging.WARNING,
            f"index_missing_sessions_{self.year}",
            "Index response still missing sessions after cache-bust",
            interval_seconds=3600,
        )
        return None

    @staticmethod
    def _has_sessions(payload: Any) -> bool:
        if not isinstance(payload, dict):
            return False
        meetings = payload.get("Meetings") or payload.get("meetings")
        sessions = payload.get("Sessions") or payload.get("sessions")
        if isinstance(meetings, list) and meetings:
            return True
        if isinstance(meetings, dict) and meetings:
            return True
        if isinstance(sessions, list) and sessions:
            return True
        if isinstance(sessions, dict) and sessions:
            return True
        return False



class TrackStatusCoordinator(DataUpdateCoordinator):
    """Coordinator for TrackStatus updates using SignalR."""

    def __init__(
        self,
        hass: HomeAssistant,
        session_coord: LiveSessionCoordinator,
        delay_seconds: int = 0,
        bus: LiveBus | None = None,
        config_entry: ConfigEntry | None = None,
        delay_controller: LiveDelayController | None = None,
        live_state: LiveAvailabilityTracker | None = None,
    ):
        super().__init__(
            hass,
            coordinator_logger("track_status", suppress_manual=True),
            name="F1 Track Status Coordinator",
            update_interval=None,
            config_entry=config_entry,
        )
        self._session = async_get_clientsession(hass)
        self._session_coord = session_coord
        self.available = True
        self._last_message = None
        self.data_list: list[dict] = []
        self._deliver_handle: Optional[asyncio.Handle] = None
        self._deliver_handles: list[asyncio.Handle] = []
        self._bus = bus
        self._unsub: Optional[Callable[[], None]] = None
        self._delay_listener: Optional[Callable[[], None]] = None
        self._t0 = None
        self._startup_cutoff = None
        self._delay = max(0, int(delay_seconds or 0))
        if delay_controller is not None:
            self._delay_listener = delay_controller.add_listener(self.set_delay)
        # Lightweight dedupe of untimestamped repeats
        self._last_untimestamped_fingerprint: str | None = None
        self._live_state_unsub: Optional[Callable[[], None]] = None
        if live_state is not None:
            self._live_state_unsub = live_state.add_listener(self._handle_live_state)

    async def async_close(self, *_):
        if self._unsub:
            try:
                self._unsub()
            except Exception:
                pass
            self._unsub = None
        if self._deliver_handle:
            try:
                self._deliver_handle.cancel()
            except Exception:
                pass
            self._deliver_handle = None
        # Cancel any queued delayed deliveries
        try:
            for h in list(self._deliver_handles):
                try:
                    h.cancel()
                except Exception:
                    pass
            self._deliver_handles.clear()
        except Exception:
            pass
        if self._delay_listener:
            try:
                self._delay_listener()
            except Exception:
                pass
            self._delay_listener = None
        if self._live_state_unsub:
            try:
                self._live_state_unsub()
            except Exception:
                pass
            self._live_state_unsub = None

    async def _async_update_data(self):
        return self._last_message

    def _on_bus_message(self, msg: dict) -> None:
        if not isinstance(msg, dict):
            return
        # Drop old messages near startup
        utc_str = (
            msg.get("Utc")
            or msg.get("utc")
            or msg.get("processedAt")
            or msg.get("timestamp")
        )
        try:
            if utc_str:
                ts = datetime.fromisoformat(str(utc_str).replace("Z", "+00:00"))
                if ts.tzinfo is None:
                    from datetime import timezone as _tz
                    ts = ts.replace(tzinfo=_tz.utc)
                if self._startup_cutoff and ts < self._startup_cutoff:
                    return
        except Exception:
            pass
        # Dedupe untimestamped exact repeats to avoid flooding when delayed
        try:
            has_ts = any(k in msg for k in ("Utc", "utc", "processedAt", "timestamp"))
        except Exception:
            has_ts = False
        if not has_ts:
            try:
                fp = json.dumps({
                    "Status": msg.get("Status"),
                    "Message": msg.get("Message") or msg.get("TrackStatus")
                }, sort_keys=True, default=str)
                if self._last_untimestamped_fingerprint == fp:
                    return
                self._last_untimestamped_fingerprint = fp
            except Exception:
                pass

        if self._delay > 0:
            # Queue each delivery independently so intermediate states (e.g. YELLOW) survive
            try:
                handle = self.hass.loop.call_later(self._delay, lambda m=msg: self._deliver(m))
                self._deliver_handles.append(handle)
            except Exception:
                # Fallback to immediate delivery
                try:
                    self._deliver(msg)
                except Exception:
                    pass
        else:
            # Immediate delivery; keep legacy single-handle for symmetry
            try:
                if self._deliver_handle:
                    self._deliver_handle.cancel()
            except Exception:
                pass
            self._deliver_handle = self.hass.loop.call_soon(lambda m=msg: self._deliver(m))

    @staticmethod
    def _parse_message(data):
        if not isinstance(data, dict):
            return None
        # Handle live feed entries
        messages = data.get("M")
        if isinstance(messages, list):
            for update in messages:
                args = update.get("A", [])
                if len(args) >= 2 and args[0] == "TrackStatus":
                    return args[1]
        # Handle RPC responses
        result = data.get("R")
        if isinstance(result, dict) and "TrackStatus" in result:
            return result.get("TrackStatus")
        return None

    def _deliver(self, msg: dict) -> None:
        self.available = True
        self._last_message = msg
        self.data_list = [msg]
        self.async_set_updated_data(msg)
        try:
            self.hass.data[LATEST_TRACK_STATUS] = msg
        except Exception:
            pass
        if _LOGGER.isEnabledFor(logging.DEBUG):
            try:
                _LOGGER.debug(
                    "TrackStatus delivered at %s status=%s message=%s",
                    dt_util.utcnow().isoformat(timespec="seconds"),
                    (msg or {}).get("Status"),
                    (msg or {}).get("Message"),
                )
            except Exception:
                pass

    async def async_config_entry_first_refresh(self):
        await super().async_config_entry_first_refresh()
        # Capture connection time and startup window
        try:
            from datetime import timezone
            self._t0 = datetime.now(timezone.utc)
            self._startup_cutoff = self._t0 - timedelta(seconds=30)
        except Exception:
            self._startup_cutoff = None
        # Subscribe to LiveBus
        try:
            self._unsub = (self._bus or self.hass.data.get(DOMAIN, {}).get("live_bus")).subscribe("TrackStatus", self._on_bus_message)  # type: ignore[attr-defined]
        except Exception:
            self._unsub = None

    def set_delay(self, seconds: int) -> None:
        new_delay = max(0, int(seconds or 0))
        if new_delay == self._delay:
            return
        self._delay = new_delay
        if self._deliver_handle:
            try:
                self._deliver_handle.cancel()
            except Exception:
                pass
            self._deliver_handle = None
        if self._deliver_handles:
            for handle in list(self._deliver_handles):
                try:
                    handle.cancel()
                except Exception:
                    pass
            self._deliver_handles.clear()

    def _handle_live_state(self, is_live: bool, reason: str | None) -> None:
        if reason == "init":
            return
        self.available = is_live
        if not is_live:
            self._last_message = None
            self.data_list = []


class SessionStatusCoordinator(DataUpdateCoordinator):
    """Coordinator for SessionStatus updates using SignalR."""

    def __init__(
        self,
        hass: HomeAssistant,
        session_coord: LiveSessionCoordinator,
        delay_seconds: int = 0,
        bus: LiveBus | None = None,
        config_entry: ConfigEntry | None = None,
        delay_controller: LiveDelayController | None = None,
        live_state: LiveAvailabilityTracker | None = None,
    ):
        super().__init__(
            hass,
            coordinator_logger("session_status", suppress_manual=True),
            name="F1 Session Status Coordinator",
            update_interval=None,
            config_entry=config_entry,
        )
        self._session = async_get_clientsession(hass)
        self._session_coord = session_coord
        self.available = True
        self._last_message = None
        self.data_list: list[dict] = []
        self._deliver_handle: Optional[asyncio.Handle] = None
        self._bus = bus
        self._unsub: Optional[Callable[[], None]] = None
        self._delay_listener: Optional[Callable[[], None]] = None
        self._delay = max(0, int(delay_seconds or 0))
        if delay_controller is not None:
            self._delay_listener = delay_controller.add_listener(self.set_delay)
        self._live_state_unsub: Optional[Callable[[], None]] = None
        if live_state is not None:
            self._live_state_unsub = live_state.add_listener(self._handle_live_state)

    async def async_close(self, *_):
        if self._unsub:
            try:
                self._unsub()
            except Exception:
                pass
            self._unsub = None
        if self._deliver_handle:
            try:
                self._deliver_handle.cancel()
            except Exception:
                pass
            self._deliver_handle = None
        if self._delay_listener:
            try:
                self._delay_listener()
            except Exception:
                pass
            self._delay_listener = None
        if self._live_state_unsub:
            try:
                self._live_state_unsub()
            except Exception:
                pass
            self._live_state_unsub = None

    async def _async_update_data(self):
        return self._last_message

    def _on_bus_message(self, msg: dict) -> None:
        if not isinstance(msg, dict):
            return
        if self._delay > 0:
            try:
                if self._deliver_handle:
                    self._deliver_handle.cancel()
            except Exception:
                pass
            self._deliver_handle = self.hass.loop.call_later(
                self._delay, lambda m=msg: self._deliver(m)
            )
        else:
            try:
                if self._deliver_handle:
                    self._deliver_handle.cancel()
            except Exception:
                pass
            self._deliver_handle = self.hass.loop.call_soon(lambda m=msg: self._deliver(m))

    @staticmethod
    def _parse_message(data):
        if not isinstance(data, dict):
            return None
        messages = data.get("M")
        if isinstance(messages, list):
            for update in messages:
                args = update.get("A", [])
                if len(args) >= 2 and args[0] == "SessionStatus":
                    return args[1]
        result = data.get("R")
        if isinstance(result, dict) and "SessionStatus" in result:
            return result.get("SessionStatus")
        return None

    def _deliver(self, msg: dict) -> None:
        self.available = True
        self._last_message = msg
        self.data_list = [msg]
        self.async_set_updated_data(msg)
        if _LOGGER.isEnabledFor(logging.DEBUG):
            try:
                _LOGGER.debug(
                    "SessionStatus delivered at %s status=%s started=%s",
                    dt_util.utcnow().isoformat(timespec="seconds"),
                    (msg or {}).get("Status"),
                    (msg or {}).get("Started"),
                )
            except Exception:
                pass

    async def async_config_entry_first_refresh(self):
        await super().async_config_entry_first_refresh()
        try:
            self._unsub = (self._bus or self.hass.data.get(DOMAIN, {}).get("live_bus")).subscribe("SessionStatus", self._on_bus_message)  # type: ignore[attr-defined]
        except Exception:
            self._unsub = None

    def set_delay(self, seconds: int) -> None:
        new_delay = max(0, int(seconds or 0))
        if new_delay == self._delay:
            return
        self._delay = new_delay
        if self._deliver_handle:
            try:
                self._deliver_handle.cancel()
            except Exception:
                pass
            self._deliver_handle = None

    def _handle_live_state(self, is_live: bool, reason: str | None) -> None:
        if reason == "init":
            return
        self.available = is_live
        if not is_live:
            self._last_message = None
            self.data_list = []


class TopThreeCoordinator(DataUpdateCoordinator):
    """Coordinator for TopThree updates using SignalR.

    Normaliserar TopThree-flÃ¶det till ett enkelt state:
        {
            "withheld": bool | None,
            "lines": [dict | None, dict | None, dict | None],
            "last_update_ts": str | None,
        }
    dÃ¤r varje line Ã¤r direkt baserad pÃ¥ feedens rader (Position, Tla, DiffToLeader osv).
    """

    def __init__(
        self,
        hass: HomeAssistant,
        session_coord: LiveSessionCoordinator,
        delay_seconds: int = 0,
        bus: LiveBus | None = None,
        config_entry: ConfigEntry | None = None,
        delay_controller: LiveDelayController | None = None,
        live_state: LiveAvailabilityTracker | None = None,
    ):
        super().__init__(
            hass,
            coordinator_logger("top_three", suppress_manual=True),
            name="F1 Top Three Coordinator",
            update_interval=None,
            config_entry=config_entry,
        )
        self._session = async_get_clientsession(hass)
        self._session_coord = session_coord
        self.available = True
        self._state: dict[str, Any] = {
            "withheld": None,
            "lines": [None, None, None],
            "last_update_ts": None,
        }
        self._deliver_handle: Optional[asyncio.Handle] = None
        self._bus = bus
        self._unsub: Optional[Callable[[], None]] = None
        self._delay_listener: Optional[Callable[[], None]] = None
        self._delay = max(0, int(delay_seconds or 0))
        if delay_controller is not None:
            self._delay_listener = delay_controller.add_listener(self.set_delay)
        self._live_state_unsub: Optional[Callable[[], None]] = None
        if live_state is not None:
            self._live_state_unsub = live_state.add_listener(self._handle_live_state)

    async def async_close(self, *_):
        if self._unsub:
            try:
                self._unsub()
            except Exception:
                pass
            self._unsub = None
        if self._deliver_handle:
            try:
                self._deliver_handle.cancel()
            except Exception:
                pass
            self._deliver_handle = None
        if self._delay_listener:
            try:
                self._delay_listener()
            except Exception:
                pass
            self._delay_listener = None
        if self._live_state_unsub:
            try:
                self._live_state_unsub()
            except Exception:
                pass
            self._live_state_unsub = None

    async def _async_update_data(self):
        return self._state

    def _handle_live_state(self, is_live: bool, reason: str | None) -> None:
        if reason == "init":
            return
        self.available = is_live
        if not is_live:
            try:
                self._state = {
                    "withheld": None,
                    "lines": [None, None, None],
                    "last_update_ts": None,
                }
            except Exception:
                pass

    def set_delay(self, seconds: int) -> None:
        new_delay = max(0, int(seconds or 0))
        if new_delay == self._delay:
            return
        self._delay = new_delay
        if self._deliver_handle:
            try:
                self._deliver_handle.cancel()
            except Exception:
                pass
            self._deliver_handle = None

    def _schedule_deliver(self) -> None:
        if self._delay > 0:
            try:
                if self._deliver_handle:
                    self._deliver_handle.cancel()
            except Exception:
                pass
            self._deliver_handle = self.hass.loop.call_later(
                self._delay, self._deliver
            )
        else:
            try:
                if self._deliver_handle:
                    self._deliver_handle.cancel()
            except Exception:
                pass
            self._deliver_handle = self.hass.loop.call_soon(self._deliver)

    def _merge_topthree(self, payload: dict) -> None:
        """Merge a TopThree payload (full snapshot or partial delta) into state."""
        if not isinstance(payload, dict):
            return

        state = self._state

        # Withheld flag (om F1 vÃ¤ljer att inte visa topp 3)
        try:
            if "Withheld" in payload:
                state["withheld"] = bool(payload.get("Withheld"))
        except Exception:
            pass

        lines = payload.get("Lines")
        cur_lines = state.get("lines") or [None, None, None]

        # Full snapshot: Lines som lista [P1, P2, P3]
        if isinstance(lines, list):
            new_lines: list[Any] = [None, None, None]
            for idx in range(3):
                try:
                    item = lines[idx]
                except Exception:
                    item = None
                new_lines[idx] = item if isinstance(item, dict) else None
            state["lines"] = new_lines
        # Delta: Lines som dict { "0": {...}, "1": {...}, "2": {...} }
        elif isinstance(lines, dict):
            for key, delta in lines.items():
                try:
                    idx = int(key)
                except Exception:
                    continue
                if idx < 0 or idx > 2:
                    continue
                if not isinstance(delta, dict):
                    continue
                base = cur_lines[idx]
                if not isinstance(base, dict):
                    base = {}
                try:
                    base.update(delta)
                except Exception:
                    # Sista fÃ¶rsvarslinje â hellre lÃ¤mna base opÃ¥verkad Ã¤n krascha
                    pass
                cur_lines[idx] = base
            state["lines"] = cur_lines

        try:
            state["last_update_ts"] = dt_util.utcnow().isoformat()
        except Exception:
            state["last_update_ts"] = None

    def _on_bus_message(self, msg: dict) -> None:
        if not isinstance(msg, dict):
            return
        try:
            self._merge_topthree(msg)
        except Exception:
            return
        self._schedule_deliver()

    def _deliver(self) -> None:
        # Pushar aktuellt state till sensorerna
        self.async_set_updated_data(self._state)

    async def async_config_entry_first_refresh(self):
        await super().async_config_entry_first_refresh()
        # Prenumerera pÃ¥ TopThree frÃ¥n LiveBus
        try:
            bus = (self._bus or self.hass.data.get(DOMAIN, {}).get("live_bus"))  # type: ignore[assignment]
        except Exception:
            bus = None
        if bus is not None:
            try:
                self._unsub = bus.subscribe("TopThree", self._on_bus_message)
            except Exception:
                self._unsub = None


class SessionInfoCoordinator(DataUpdateCoordinator):
    """Coordinator for SessionInfo updates using SignalR."""

    def __init__(
        self,
        hass: HomeAssistant,
        session_coord: LiveSessionCoordinator,
        delay_seconds: int = 0,
        bus: LiveBus | None = None,
        config_entry: ConfigEntry | None = None,
        delay_controller: LiveDelayController | None = None,
        live_state: LiveAvailabilityTracker | None = None,
    ):
        super().__init__(
            hass,
            coordinator_logger("session_info", suppress_manual=True),
            name="F1 Session Info Coordinator",
            update_interval=None,
            config_entry=config_entry,
        )
        self._session = async_get_clientsession(hass)
        self._session_coord = session_coord
        self.available = True
        self._last_message = None
        self.data_list: list[dict] = []
        self._deliver_handle: Optional[asyncio.Handle] = None
        self._bus = bus
        self._unsub: Optional[Callable[[], None]] = None
        self._delay_listener: Optional[Callable[[], None]] = None
        self._delay = max(0, int(delay_seconds or 0))
        if delay_controller is not None:
            self._delay_listener = delay_controller.add_listener(self.set_delay)
        self._live_state_unsub: Optional[Callable[[], None]] = None
        if live_state is not None:
            self._live_state_unsub = live_state.add_listener(self._handle_live_state)

    async def async_close(self, *_):
        if self._unsub:
            try:
                self._unsub()
            except Exception:
                pass
            self._unsub = None
        if self._deliver_handle:
            try:
                self._deliver_handle.cancel()
            except Exception:
                pass
            self._deliver_handle = None
        if self._delay_listener:
            try:
                self._delay_listener()
            except Exception:
                pass
            self._delay_listener = None
        if self._live_state_unsub:
            try:
                self._live_state_unsub()
            except Exception:
                pass
            self._live_state_unsub = None

    async def _async_update_data(self):
        return self._last_message

    def _on_bus_message(self, msg: dict) -> None:
        if not isinstance(msg, dict):
            return
        if self._delay > 0:
            try:
                if self._deliver_handle:
                    self._deliver_handle.cancel()
            except Exception:
                pass
            self._deliver_handle = self.hass.loop.call_later(
                self._delay, lambda m=msg: self._deliver(m)
            )
        else:
            try:
                if self._deliver_handle:
                    self._deliver_handle.cancel()
            except Exception:
                pass
            self._deliver_handle = self.hass.loop.call_soon(lambda m=msg: self._deliver(m))

    @staticmethod
    def _parse_message(data):
        if not isinstance(data, dict):
            return None
        messages = data.get("M")
        if isinstance(messages, list):
            for update in messages:
                args = update.get("A", [])
                if len(args) >= 2 and args[0] == "SessionInfo":
                    return args[1]
        result = data.get("R")
        if isinstance(result, dict) and "SessionInfo" in result:
            return result.get("SessionInfo")
        return None

    def _deliver(self, msg: dict) -> None:
        self.available = True
        self._last_message = msg
        self.data_list = [msg]
        self.async_set_updated_data(msg)
        if _LOGGER.isEnabledFor(logging.DEBUG):
            try:
                name = (msg or {}).get("Name")
                t = (msg or {}).get("Type")
                _LOGGER.debug(
                    "SessionInfo delivered at %s type=%s name=%s",
                    dt_util.utcnow().isoformat(timespec="seconds"),
                    t,
                    name,
                )
            except Exception:
                pass

    async def async_config_entry_first_refresh(self):
        await super().async_config_entry_first_refresh()
        try:
            self._unsub = (self._bus or self.hass.data.get(DOMAIN, {}).get("live_bus")).subscribe("SessionInfo", self._on_bus_message)  # type: ignore[attr-defined]
        except Exception:
            self._unsub = None

    def set_delay(self, seconds: int) -> None:
        new_delay = max(0, int(seconds or 0))
        if new_delay == self._delay:
            return
        self._delay = new_delay
        if self._deliver_handle:
            try:
                self._deliver_handle.cancel()
            except Exception:
                pass
            self._deliver_handle = None

    def _handle_live_state(self, is_live: bool, reason: str | None) -> None:
        if reason == "init":
            return
        self.available = is_live
        if not is_live:
            self._last_message = None
            self.data_list = []
